# Load the TensorBoard notebook extension.
%load_ext tensorboard


from datetime import datetime
from packaging import version

import tensorflow as tf
from tensorflow import keras

# My imports
import os
import tensorflow_hub as hub
from tensorflow.keras import layers
from objective_func import macro_soft_f1, macro_f1
from loader.mimic_cxr_jpg_loader import MIMIC_CXR_JPG_Loader
from utils.augmentation import preprocess_image
from lars_optimizer import LARSOptimizer


# Global variables
project_folder = os.getcwd()
BASE_MODEL_PATH = './base-models/simclr/r152_2x_sk1/hub/'
BATCH_SIZE = 4
LEARNING_RATE = 0.1
EPOCHS = 1
MOMENTUM = 0.9
WEIGHT_DECAY = 1e-6
IMAGE_SIZE = (448, 448)
CHANNELS = 3
num_classes = 14


print("TensorFlow version: ", tf.__version__)
assert version.parse(tf.__version__).release[0] >= 2, \
    "This notebook requires TensorFlow 2.0 or above."


import tensorboard
tensorboard.__version__


# Clear any logs from previous runs
!rm -rf ./out/board/





hub_path = os.path.join(project_folder, BASE_MODEL_PATH)
try:
    feature_extractor_layer = hub.KerasLayer(hub_path, input_shape=(*IMAGE_SIZE, CHANNELS), trainable=False)
except:
    print(f"""The model {hub_path} did not load. Please verify the model path. It is also worth considering that the model might still be in the process of being uploaded to the designated location. If you have recently uploaded it to a notebook, there could be delays associated with the upload.""")
    raise

#------------------- SETUP TRAINING HEAD -------------------#

model = tf.keras.Sequential([
    feature_extractor_layer,
    layers.Dense(1024, activation='relu', name='hidden_layer'),
    layers.Dense(num_classes, activation='sigmoid', name='multi-label_classifier')
])

# TEMP for debugging
print(model.summary())


optimizer = tf.keras.optimizers.Adam(
    learning_rate=LEARNING_RATE,
    weight_decay=WEIGHT_DECAY)
optimizer.exclude_from_weight_decay(var_names=['batch_normalization', 'bias', 'head_supervised'])

model.compile(
    optimizer=optimizer,
    loss=macro_soft_f1,
    metrics=[macro_f1])


# Define the Keras TensorBoard callback.
logdir="out/board" + datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)


def _preprocess_train(x, y, info=None):
    x = preprocess_image(
        x, *IMAGE_SIZE,
        is_training=True, color_distort=False, crop='Center')
    return x, y

def _preprocess_val(x, y, info=None):
    x = preprocess_image(
        x, *IMAGE_SIZE,
        is_training=False, color_distort=False, crop='Center')
    return x, y


customLoader = MIMIC_CXR_JPG_Loader({'train': 5000, 'validate': 200, 'test': 0}, project_folder)
train_tfds, val_tfds, test_tfds = customLoader.load()
train_tfds = train_tfds.shuffle(buffer_size=2*BATCH_SIZE)
batched_train_tfds = train_tfds.map(_preprocess_train).batch(BATCH_SIZE)


start = time()
history = model.fit(batched_train_tfds,
                  epochs=EPOCHS,
                  validation_data=batched_val_tfds)
print('\nTraining took {}'.format(print_time(time()-start)))
