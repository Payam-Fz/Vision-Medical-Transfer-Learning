{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:18.467016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 19:37:19.140141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:19.933992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-13 20:59:59.046425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 20:59:59.616360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-13 21:00:00.738881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 21:00:00.777543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0313 21:00:01.402586 140455175722816 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "@_@\tStart: 2024-03-13_2100\n",
      "@_@\t\n",
      "@_@\tNumber of GPUs: 1\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 5000\n",
      "@_@\tEpochs: 10\n",
      "@_@\tBatch size per GPU: 16.0\n",
      "@_@\tOverall Batch size: 16\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\ttotal_size: 377110\n",
      "@_@\tsplit_size: {'train': 5000, 'validate': 741, 'test': 0}\n",
      "@_@\tsplit_size_frac: {'train': 0.013258730874280714, 'validate': 0.0019649439155684017, 'test': 0.0}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0313 21:00:49.186663 140455175722816 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [16, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [16, 7]\n",
      "2024-03-13 21:00:56.912094: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:00:56.912147: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-13 21:00:56.912232: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-13 21:00:57.014853: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:00:57.016042: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.396126 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.398212 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.399423 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.400036 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.402874 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.403472 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.404575 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.405161 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,856\n",
      "Trainable params: 40,438,855\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "2024-03-13 21:00:57.420339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 5000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0313 21:00:58.566590 140435578934848 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.683192 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.684458 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-03-13 21:01:08.604326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-13 21:01:14.519960: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fbc84005d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-13 21:01:14.520007: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-13 21:01:14.533653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-13 21:01:14.638154: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  4/313 [..............................] - ETA: 4:10 - loss: 0.8100 - macro_f1: 0.1200 - binary_crossentropy: 15.3029WARNING:tensorflow:Trace already enabled\n",
      "W0313 21:01:21.683152 140455175722816 summary_ops_v2.py:1325] Trace already enabled\n",
      "2024-03-13 21:01:21.683342: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:01:21.683382: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "  9/313 [..............................] - ETA: 11:20 - loss: 0.7634 - macro_f1: 0.1388 - binary_crossentropy: 8.00062024-03-13 21:01:40.024734: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2024-03-13 21:01:40.035891: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2024-03-13 21:01:40.116917: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 3235 callback api events and 3117 activity events. \n",
      "2024-03-13 21:01:40.142220: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:01:40.193099: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16_2024-03-13_2100/board/plugins/profile/2024_03_13_21_01_40/visionsw4.xplane.pb\n",
      "134/313 [===========>..................] - ETA: 9:16 - loss: 0.7574 - macro_f1: 0.0307 - binary_crossentropy: 1.0247^C\n"
     ]
    }
   ],
   "source": [
    "!python ../neural_nets/vgg16_mgpu.py \\\n",
    "    --ouput_name=vgg16 --gpu_mem_limit=10240 \\\n",
    "    --learning_rate=1e-3 --epochs=10 \\\n",
    "    --image_size=448 --batch_size=16 --train_size=5000 \\\n",
    "    --transfer_learning=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
