{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:18.467016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 19:37:19.140141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:19.933992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../neural_nets/vgg16.py \\\n",
    "    --ouput_name=test \\\n",
    "    --learning_rate=1e-3 --image_size=448 --epochs=2 --batch_size=64 --train_size=65536 \\\n",
    "    --mode=train_then_eval --transfer_learning=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-13 20:59:59.046425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 20:59:59.616360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-13 21:00:00.738881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 21:00:00.777543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0313 21:00:01.402586 140455175722816 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "@_@\tStart: 2024-03-13_2100\n",
      "@_@\t\n",
      "@_@\tNumber of GPUs: 1\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 5000\n",
      "@_@\tEpochs: 10\n",
      "@_@\tBatch size per GPU: 16.0\n",
      "@_@\tOverall Batch size: 16\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\ttotal_size: 377110\n",
      "@_@\tsplit_size: {'train': 5000, 'validate': 741, 'test': 0}\n",
      "@_@\tsplit_size_frac: {'train': 0.013258730874280714, 'validate': 0.0019649439155684017, 'test': 0.0}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0313 21:00:49.186663 140455175722816 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [16, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [16, 7]\n",
      "2024-03-13 21:00:56.912094: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:00:56.912147: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-13 21:00:56.912232: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-13 21:00:57.014853: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:00:57.016042: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.396126 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.398212 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.399423 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.400036 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.402874 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.403472 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.404575 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.405161 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,856\n",
      "Trainable params: 40,438,855\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "2024-03-13 21:00:57.420339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 5000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0313 21:00:58.566590 140435578934848 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.683192 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.684458 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-03-13 21:01:08.604326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-13 21:01:14.519960: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fbc84005d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-13 21:01:14.520007: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-13 21:01:14.533653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-13 21:01:14.638154: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  4/313 [..............................] - ETA: 4:10 - loss: 0.8100 - macro_f1: 0.1200 - binary_crossentropy: 15.3029WARNING:tensorflow:Trace already enabled\n",
      "W0313 21:01:21.683152 140455175722816 summary_ops_v2.py:1325] Trace already enabled\n",
      "2024-03-13 21:01:21.683342: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:01:21.683382: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "  9/313 [..............................] - ETA: 11:20 - loss: 0.7634 - macro_f1: 0.1388 - binary_crossentropy: 8.00062024-03-13 21:01:40.024734: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2024-03-13 21:01:40.035891: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2024-03-13 21:01:40.116917: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 3235 callback api events and 3117 activity events. \n",
      "2024-03-13 21:01:40.142220: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:01:40.193099: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16_2024-03-13_2100/board/plugins/profile/2024_03_13_21_01_40/visionsw4.xplane.pb\n",
      "134/313 [===========>..................] - ETA: 9:16 - loss: 0.7574 - macro_f1: 0.0307 - binary_crossentropy: 1.0247^C\n"
     ]
    }
   ],
   "source": [
    "# Multi-GPU\n",
    "!python ../neural_nets/vgg16_mgpu.py \\\n",
    "    --ouput_name=vgg16 --gpu_mem_limit=10240 \\\n",
    "    --learning_rate=1e-3 --epochs=10 \\\n",
    "    --image_size=448 --batch_size=16 --train_size=5000 \\\n",
    "    --transfer_learning=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-27 03:06:45.056828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 03:06:45.581609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-27 03:06:45.581686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-27 03:06:45.581694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-27 03:06:46.608432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.642948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.643160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.643560: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 03:06:46.644442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.644645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.644802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\tCode version: 2\n",
      "@_@\tsubclassed + bce loss + large batch\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-03-27_0306\n",
      "@_@\t\n",
      "@_@\tMode: eval\n",
      "@_@\tUnfreeze blocks: 0\n",
      "@_@\tContinue from checkpoint: ./out_archive/vgg16-fixed-loss-memory/vgg16-all-frozen_2024-03-20_1758/model/checkpoints\n",
      "@_@\t\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 32\n",
      "@_@\tBatch size: 32\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tEpochs: 10\n",
      "@_@\tLearning Rate: 0.1\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tCPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 94539\n",
      "@_@\tsplit_size: {'train': 32, 'validate': 741, 'test': 500}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0327 03:07:31.249855 134224442926912 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [32, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [32, 7]\n",
      "2024-03-27 03:07:33.261423: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-27 03:07:33.261488: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-27 03:07:33.261609: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-27 03:07:33.406523: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-27 03:07:33.407752: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,855\n",
      "Trainable params: 25,724,167\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Total trainable weights: 6\n",
      "my_fc_1/kernel:0\n",
      "my_fc_1/bias:0\n",
      "my_fc_2/kernel:0\n",
      "my_fc_2/bias:0\n",
      "my_output/kernel:0\n",
      "my_output/bias:0\n",
      "2024-03-27 03:07:45.755973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 219 of 320\n",
      "2024-03-27 03:07:49.714532: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2024-03-27 03:07:52.494840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-eval_2024-03-27_0306/figs/predict_sample.png\n",
      "2024-03-27 03:08:15.531055: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 226 of 320\n",
      "2024-03-27 03:08:19.432564: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a11c45c5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0327 03:08:26.132805 134224442926912 polymorphic_function.py:154] 5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a11c45c5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a11c49ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0327 03:08:26.180053 134224442926912 polymorphic_function.py:154] 6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a11c49ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "total_samples <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=16>\n",
      "@_@\tbinary_crossentropy: 0.45600390434265137\n",
      "@_@\tAUC: 0.7501763701438904\n",
      "@_@\tmacro_f1_score: 0.33338695764541626\n",
      "@_@\tsoft_f1_loss: 0.6475182175636292\n",
      "@_@\tglobal_accuracy: 0.7714285254478455\n",
      "@_@\tglobal_precision: 0.5749470591545105\n",
      "@_@\tglobal_recall: 0.48433372378349304\n",
      "@_@\t\n",
      "@_@\tDONE!\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "W0327 03:08:37.932004 134224442926912 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "W0327 03:08:37.932121 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "W0327 03:08:37.932162 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "W0327 03:08:37.932197 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "W0327 03:08:37.932228 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "W0327 03:08:37.932259 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "W0327 03:08:37.932289 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "W0327 03:08:37.932318 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "W0327 03:08:37.932348 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "W0327 03:08:37.932377 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "W0327 03:08:37.932407 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "W0327 03:08:37.932437 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "W0327 03:08:37.932466 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    }
   ],
   "source": [
    "!python ../neural_nets/vgg16.py \\\n",
    "    --ouput_name=vgg16-eval \\\n",
    "    --image_size=448 --batch_size=32 --train_size=32 \\\n",
    "    --mode=eval --unfreeze_blocks=0 \\\n",
    "    --load_checkpoint=./out_archive/vgg16-fixed-loss-memory/vgg16-all-frozen_2024-03-20_1758/model/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-18 19:43:27.478057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 19:43:28.026217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-18 19:43:28.026324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-18 19:43:28.026332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-18 19:43:29.106692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.146669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.146856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.147203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 19:43:29.148312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.148460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.148587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.592620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.592839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.592995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.593120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\tCode version: 4\n",
      "@_@\tsubclassed + bce loss\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-03-18_1943\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 64\n",
      "@_@\tEpochs: 200\n",
      "@_@\tGlobal Batch size: 32\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\t\n",
      "@_@\tIs Transfer learning: True\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 94539\n",
      "@_@\tsplit_size: {'train': 64, 'validate': 0, 'test': 0}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0318 19:44:15.533369 140411098928960 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "2024-03-18 19:44:25.860098: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 57 of 64\n",
      "2024-03-18 19:44:26.911557: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "@_@\tShape of image batch: [32, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [32, 7]\n",
      "2024-03-18 19:44:28.337490: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-18 19:44:28.337505: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-18 19:44:28.337548: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-18 19:44:28.448918: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-18 19:44:28.450279: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,857\n",
      "Trainable params: 25,724,167\n",
      "Non-trainable params: 14,714,690\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0318 19:44:29.379021 140411098928960 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2024-03-18 19:44:40.952868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-18 19:44:50.648006: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55bf85311be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-18 19:44:50.648096: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-18 19:44:50.656895: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-18 19:44:50.784702: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2/2 [==============================] - 23s 412ms/step - loss: 2.1239 - macro_f1: 0.1455 - macro_soft_f1: 0.7982\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 2.5927 - macro_f1: 0.1443 - macro_soft_f1: 0.8627\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 1.5885 - macro_f1: 0.2689 - macro_soft_f1: 0.7264\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 1.2809 - macro_f1: 0.3479 - macro_soft_f1: 0.6685\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.8709 - macro_f1: 0.3920 - macro_soft_f1: 0.6227\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.4744 - macro_f1: 0.6552 - macro_soft_f1: 0.4286\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.2771 - macro_f1: 0.6913 - macro_soft_f1: 0.3520\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.4140 - macro_f1: 0.4189 - macro_soft_f1: 0.5497\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.1827 - macro_f1: 0.7213 - macro_soft_f1: 0.3035\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.1185 - macro_f1: 0.8743 - macro_soft_f1: 0.1660\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 12s 973ms/step - loss: 0.1313 - macro_f1: 0.8301 - macro_soft_f1: 0.2280\n",
      "Epoch 12/200\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.1576 - macro_f1: 0.7921 - macro_soft_f1: 0.2624WARNING:tensorflow:Trace already enabled\n",
      "W0318 19:47:00.498482 140411098928960 summary_ops_v2.py:1325] Trace already enabled\n",
      "2024-03-18 19:47:00.498640: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-18 19:47:00.498658: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.1341 - macro_f1: 0.8517 - macro_soft_f1: 0.2397\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0882 - macro_f1: 0.9242 - macro_soft_f1: 0.1697\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0674 - macro_f1: 0.9670 - macro_soft_f1: 0.0953\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0504 - macro_f1: 0.8056 - macro_soft_f1: 0.1485\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0503 - macro_f1: 0.8184 - macro_soft_f1: 0.1900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0302 - macro_f1: 0.9660 - macro_soft_f1: 0.0631\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0240 - macro_f1: 0.9921 - macro_soft_f1: 0.0370\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0185 - macro_f1: 1.0000 - macro_soft_f1: 0.0339\n",
      "Epoch 20/200\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0156 - macro_f1: 1.0000 - macro_soft_f1: 0.02762024-03-18 19:48:36.374285: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2024-03-18 19:48:36.379334: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2024-03-18 19:48:36.449257: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 6518 callback api events and 5821 activity events. \n",
      "2024-03-18 19:48:36.479617: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-18 19:48:36.567421: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-transfer-miniBatchTest_2024-03-18_1943/board/plugins/profile/2024_03_18_19_48_36/visionsw4.xplane.pb\n",
      "2/2 [==============================] - 13s 3s/step - loss: 0.0179 - macro_f1: 0.9958 - macro_soft_f1: 0.0318\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 12s 970ms/step - loss: 0.0176 - macro_f1: 0.9231 - macro_soft_f1: 0.1016\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0161 - macro_f1: 0.9286 - macro_soft_f1: 0.1109\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0135 - macro_f1: 0.9286 - macro_soft_f1: 0.0942\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0116 - macro_f1: 0.9286 - macro_soft_f1: 0.0948\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0102 - macro_f1: 1.0000 - macro_soft_f1: 0.0205\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0092 - macro_f1: 1.0000 - macro_soft_f1: 0.0189\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0082 - macro_f1: 1.0000 - macro_soft_f1: 0.0169\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0074 - macro_f1: 1.0000 - macro_soft_f1: 0.0129\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0071 - macro_f1: 1.0000 - macro_soft_f1: 0.0131\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0068 - macro_f1: 1.0000 - macro_soft_f1: 0.0116\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 12s 962ms/step - loss: 0.0064 - macro_f1: 1.0000 - macro_soft_f1: 0.0106\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0060 - macro_f1: 1.0000 - macro_soft_f1: 0.0105\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0057 - macro_f1: 1.0000 - macro_soft_f1: 0.0096\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0053 - macro_f1: 1.0000 - macro_soft_f1: 0.0091\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0052 - macro_f1: 1.0000 - macro_soft_f1: 0.0088\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0049 - macro_f1: 1.0000 - macro_soft_f1: 0.0083\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0048 - macro_f1: 1.0000 - macro_soft_f1: 0.0084\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0045 - macro_f1: 1.0000 - macro_soft_f1: 0.0079\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0044 - macro_f1: 1.0000 - macro_soft_f1: 0.0076\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0042 - macro_f1: 1.0000 - macro_soft_f1: 0.0070\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0041 - macro_f1: 0.9286 - macro_soft_f1: 0.0780\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0040 - macro_f1: 1.0000 - macro_soft_f1: 0.0070\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0039 - macro_f1: 1.0000 - macro_soft_f1: 0.0069\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0038 - macro_f1: 1.0000 - macro_soft_f1: 0.0063\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0037 - macro_f1: 1.0000 - macro_soft_f1: 0.0058\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0036 - macro_f1: 1.0000 - macro_soft_f1: 0.0059\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0035 - macro_f1: 1.0000 - macro_soft_f1: 0.0059\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0034 - macro_f1: 1.0000 - macro_soft_f1: 0.0056\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0033 - macro_f1: 1.0000 - macro_soft_f1: 0.0053\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0033 - macro_f1: 0.9286 - macro_soft_f1: 0.0766\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0032 - macro_f1: 0.9286 - macro_soft_f1: 0.0766\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0031 - macro_f1: 1.0000 - macro_soft_f1: 0.0067\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0031 - macro_f1: 1.0000 - macro_soft_f1: 0.0054\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0030 - macro_f1: 1.0000 - macro_soft_f1: 0.0051\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0029 - macro_f1: 1.0000 - macro_soft_f1: 0.0050\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0029 - macro_f1: 0.8571 - macro_soft_f1: 0.1473\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0028 - macro_f1: 1.0000 - macro_soft_f1: 0.0048\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0028 - macro_f1: 0.9286 - macro_soft_f1: 0.0759\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0027 - macro_f1: 0.9286 - macro_soft_f1: 0.0757\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0027 - macro_f1: 1.0000 - macro_soft_f1: 0.0045\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0026 - macro_f1: 1.0000 - macro_soft_f1: 0.0048\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0026 - macro_f1: 1.0000 - macro_soft_f1: 0.0044\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0025 - macro_f1: 1.0000 - macro_soft_f1: 0.0044\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0025 - macro_f1: 1.0000 - macro_soft_f1: 0.0045\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0024 - macro_f1: 0.9286 - macro_soft_f1: 0.0756\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0024 - macro_f1: 1.0000 - macro_soft_f1: 0.0040\n",
      "Epoch 67/200\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/jupyter/../neural_nets/vgg16_test.py\", line 346, in <module>\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch Testing\n",
    "!python ../neural_nets/vgg16_test.py \\\n",
    "    --ouput_name=vgg16-transfer-miniBatchTest \\\n",
    "    --learning_rate=1e-3 --image_size=448 --epochs=200 --batch_size=32 --train_size=64 \\\n",
    "    --transfer_learning=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
