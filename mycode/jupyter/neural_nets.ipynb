{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:18.467016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 19:37:19.140141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:19.933992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-29 14:29:02.502811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 14:29:03.019637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-29 14:29:03.019744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-29 14:29:03.019753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-29 14:29:04.003071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.037997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.038208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.038570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 14:29:04.039506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.039660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.039786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.463418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.463648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.463774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-29 14:29:04.463874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\tCode version: 2\n",
      "@_@\tsubclassed + bce loss + large batch\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-03-29_1429\n",
      "@_@\t\n",
      "@_@\tMode: train_then_eval\n",
      "@_@\tUnfreeze blocks: start 0, end 1\n",
      "@_@\tContinue from checkpoint: ./out/vgg16-gradual_2024-03-28_1652/1_unfrozen_block/model/checkpoints\n",
      "@_@\t\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 32\n",
      "@_@\tBatch size: 32\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tMax Epochs per training round: 20\n",
      "@_@\tDefault Learning Rate: 1e-05\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tCPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 9\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax' 'Fracture' 'Support Devices']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 112134\n",
      "@_@\tsplit_size: {'train': 32, 'validate': 889, 'test': 512}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0329 14:29:50.755036 132233308432192 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [32, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [32, 9]\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,439,113\n",
      "Trainable params: 25,724,425\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "2024-03-29 14:29:53.083046: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-29 14:29:53.083116: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-29 14:29:53.083256: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-29 14:29:53.210006: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-29 14:29:53.211159: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "@_@\tUnfreezing 0 blocks...\n",
      "@_@\tLearning rate = 0.001\n",
      "@_@\tTotal trainable weights: 6\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLoading weights from /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/./out/vgg16-gradual_2024-03-28_1652/1_unfrozen_block/model/checkpoints/epoch-04_validloss-0.3906.ckpt\n",
      "@_@\t\n",
      "@_@\t------------------ Training ------------------\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0329 14:29:55.789063 132233308432192 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2024-03-29 14:29:58.837149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-29 14:30:08.499130: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x78420c070160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-29 14:30:08.499226: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-29 14:30:08.510912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-29 14:30:08.640315: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4300 - macro_f1_score: 0.1605 - soft_f1_loss: 0.7123 - AUC: 0.7241 - global_accuracy: 0.7917 - global_precision: 0.6538 - global_recall: 0.2500\n",
      "Epoch 1: val_loss improved from inf to 0.40284, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/0_unfrozen_block/model/checkpoints/epoch-01_valloss-0.4028.ckpt\n",
      "1/1 [==============================] - 72s 72s/step - loss: 0.4300 - macro_f1_score: 0.1605 - soft_f1_loss: 0.7123 - AUC: 0.7241 - global_accuracy: 0.7917 - global_precision: 0.6538 - global_recall: 0.2500 - val_loss: 0.4028 - val_macro_f1_score: 0.2965 - val_soft_f1_loss: 0.7038 - val_AUC: 0.7252 - val_global_accuracy: 0.8025 - val_global_precision: 0.5787 - val_global_recall: 0.5209\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4024 - macro_f1_score: 0.3095 - soft_f1_loss: 0.6804 - AUC: 0.7751 - global_accuracy: 0.8299 - global_precision: 0.6863 - global_recall: 0.5147\n",
      "Epoch 2: val_loss did not improve from 0.40284\n",
      "1/1 [==============================] - 46s 46s/step - loss: 0.4024 - macro_f1_score: 0.3095 - soft_f1_loss: 0.6804 - AUC: 0.7751 - global_accuracy: 0.8299 - global_precision: 0.6863 - global_recall: 0.5147 - val_loss: 0.4213 - val_macro_f1_score: 0.3073 - val_soft_f1_loss: 0.7057 - val_AUC: 0.7169 - val_global_accuracy: 0.7910 - val_global_precision: 0.5450 - val_global_recall: 0.5519\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3826 - macro_f1_score: 0.3881 - soft_f1_loss: 0.6540 - AUC: 0.8257 - global_accuracy: 0.8542 - global_precision: 0.7241 - global_recall: 0.6176\n",
      "Epoch 3: val_loss did not improve from 0.40284\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.3826 - macro_f1_score: 0.3881 - soft_f1_loss: 0.6540 - AUC: 0.8257 - global_accuracy: 0.8542 - global_precision: 0.7241 - global_recall: 0.6176 - val_loss: 0.4174 - val_macro_f1_score: 0.2941 - val_soft_f1_loss: 0.7078 - val_AUC: 0.7049 - val_global_accuracy: 0.7899 - val_global_precision: 0.5473 - val_global_recall: 0.5109\n",
      "Epoch 3: early stopping\n",
      "@_@\t\n",
      "@_@\t------------------ Result ------------------\n",
      "@_@\tTraining took 0h:2m:43s\n",
      "@_@\thistory of metrics:\n",
      "@_@\t\tloss: [0.4299893379211426, 0.40242063999176025, 0.38262832164764404]\n",
      "@_@\t\tmacro_f1_score: [0.160502091050148, 0.30951249599456787, 0.38807928562164307]\n",
      "@_@\t\tsoft_f1_loss: [0.7122858762741089, 0.6804019212722778, 0.6539526581764221]\n",
      "@_@\t\tAUC: [0.7240632176399231, 0.7750775814056396, 0.8256943821907043]\n",
      "@_@\t\tglobal_accuracy: [0.7916666865348816, 0.8298611044883728, 0.8541666865348816]\n",
      "@_@\t\tglobal_precision: [0.6538461446762085, 0.686274528503418, 0.7241379022598267]\n",
      "@_@\t\tglobal_recall: [0.25, 0.5147058963775635, 0.6176470518112183]\n",
      "@_@\t\tval_loss: [0.4028361737728119, 0.4212532043457031, 0.41742992401123047]\n",
      "@_@\t\tval_macro_f1_score: [0.29646334052085876, 0.30728837847709656, 0.2941338121891022]\n",
      "@_@\t\tval_soft_f1_loss: [0.7038029432296753, 0.7056683897972107, 0.7077532410621643]\n",
      "@_@\t\tval_AUC: [0.7252492904663086, 0.7169099450111389, 0.7048803567886353]\n",
      "@_@\t\tval_global_accuracy: [0.8025148510932922, 0.7909573316574097, 0.7898560762405396]\n",
      "@_@\t\tval_global_precision: [0.5787030458450317, 0.5449936985969543, 0.5472904443740845]\n",
      "@_@\t\tval_global_recall: [0.5209482312202454, 0.5519285798072815, 0.5108951926231384]\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/0_unfrozen_block/figs/learning_curve.png\n",
      "@_@\tValidation loss: 0.42\n",
      "@_@\tValidation Macro F1-score: 0.29\n",
      "W0329 14:32:39.986833 132233308432192 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/0_unfrozen_block/model/saved_model/assets\n",
      "I0329 14:32:46.445924 132233308432192 builder_impl.py:797] Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/0_unfrozen_block/model/saved_model/assets\n",
      "@_@\tSaved model to: \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/0_unfrozen_block/model/saved_model\"\n",
      "2024-03-29 14:32:46.727369: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-29 14:32:46.727466: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-29 14:32:46.947158: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-29 14:32:46.949779: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "@_@\tUnfreezing 1 blocks...\n",
      "@_@\tLearning rate = 0.0001\n",
      "@_@\tTotal trainable weights: 12\n",
      "@_@\t\tblock5_conv1/kernel:0\n",
      "@_@\t\tblock5_conv1/bias:0\n",
      "@_@\t\tblock5_conv2/kernel:0\n",
      "@_@\t\tblock5_conv2/bias:0\n",
      "@_@\t\tblock5_conv3/kernel:0\n",
      "@_@\t\tblock5_conv3/bias:0\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLoading weights from /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/0_unfrozen_block/model/checkpoints/epoch-01_valloss-0.4028.ckpt\n",
      "@_@\t\n",
      "@_@\t------------------ Training ------------------\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3998 - macro_f1_score: 0.2995 - soft_f1_loss: 0.6788 - AUC: 0.7623 - global_accuracy: 0.8229 - global_precision: 0.6667 - global_recall: 0.5000\n",
      "Epoch 1: val_loss improved from inf to 0.48058, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/1_unfrozen_block/model/checkpoints/epoch-01_valloss-0.4806.ckpt\n",
      "1/1 [==============================] - 56s 56s/step - loss: 0.3998 - macro_f1_score: 0.2995 - soft_f1_loss: 0.6788 - AUC: 0.7623 - global_accuracy: 0.8229 - global_precision: 0.6667 - global_recall: 0.5000 - val_loss: 0.4806 - val_macro_f1_score: 0.0993 - val_soft_f1_loss: 0.7833 - val_AUC: 0.6404 - val_global_accuracy: 0.7855 - val_global_precision: 0.5702 - val_global_recall: 0.2739\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4844 - macro_f1_score: 0.1097 - soft_f1_loss: 0.7541 - AUC: 0.7417 - global_accuracy: 0.7743 - global_precision: 0.5517 - global_recall: 0.2353\n",
      "Epoch 2: val_loss did not improve from 0.48058\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.4844 - macro_f1_score: 0.1097 - soft_f1_loss: 0.7541 - AUC: 0.7417 - global_accuracy: 0.7743 - global_precision: 0.5517 - global_recall: 0.2353 - val_loss: 0.5828 - val_macro_f1_score: 0.0863 - val_soft_f1_loss: 0.8110 - val_AUC: 0.6603 - val_global_accuracy: 0.7706 - val_global_precision: 0.4997 - val_global_recall: 0.1231\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5407 - macro_f1_score: 0.1089 - soft_f1_loss: 0.7765 - AUC: 0.7082 - global_accuracy: 0.7812 - global_precision: 0.6471 - global_recall: 0.1618\n",
      "Epoch 3: val_loss did not improve from 0.48058\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.5407 - macro_f1_score: 0.1089 - soft_f1_loss: 0.7765 - AUC: 0.7082 - global_accuracy: 0.7812 - global_precision: 0.6471 - global_recall: 0.1618 - val_loss: 0.5336 - val_macro_f1_score: 0.2456 - val_soft_f1_loss: 0.7239 - val_AUC: 0.6413 - val_global_accuracy: 0.7191 - val_global_precision: 0.4077 - val_global_recall: 0.5011\n",
      "Epoch 3: early stopping\n",
      "@_@\t\n",
      "@_@\t------------------ Result ------------------\n",
      "@_@\tTraining took 0h:2m:24s\n",
      "@_@\thistory of metrics:\n",
      "@_@\t\tloss: [0.3997684121131897, 0.484427273273468, 0.5406631827354431]\n",
      "@_@\t\tmacro_f1_score: [0.29954901337623596, 0.10968661308288574, 0.10891523957252502]\n",
      "@_@\t\tsoft_f1_loss: [0.678783118724823, 0.7541060447692871, 0.7765083312988281]\n",
      "@_@\t\tAUC: [0.7622544169425964, 0.7417036294937134, 0.7082493305206299]\n",
      "@_@\t\tglobal_accuracy: [0.8229166865348816, 0.7743055820465088, 0.78125]\n",
      "@_@\t\tglobal_precision: [0.6666666865348816, 0.5517241358757019, 0.6470588445663452]\n",
      "@_@\t\tglobal_recall: [0.5, 0.23529411852359772, 0.1617647111415863]\n",
      "@_@\t\tval_loss: [0.480579674243927, 0.5827609300613403, 0.5336470603942871]\n",
      "@_@\t\tval_macro_f1_score: [0.09934709966182709, 0.08629591017961502, 0.24558241665363312]\n",
      "@_@\t\tval_soft_f1_loss: [0.7833161354064941, 0.81096351146698, 0.723941445350647]\n",
      "@_@\t\tval_AUC: [0.6404322385787964, 0.6603024005889893, 0.6412742137908936]\n",
      "@_@\t\tval_global_accuracy: [0.7854514718055725, 0.7706002593040466, 0.7190575003623962]\n",
      "@_@\t\tval_global_precision: [0.5702153444290161, 0.4996921122074127, 0.4077329933643341]\n",
      "@_@\t\tval_global_recall: [0.27386754751205444, 0.12309715896844864, 0.5011382699012756]\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/1_unfrozen_block/figs/learning_curve.png\n",
      "@_@\tValidation loss: 0.53\n",
      "@_@\tValidation Macro F1-score: 0.25\n",
      "W0329 14:35:14.529104 132233308432192 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/1_unfrozen_block/model/saved_model/assets\n",
      "I0329 14:35:21.884205 132233308432192 builder_impl.py:797] Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/1_unfrozen_block/model/saved_model/assets\n",
      "@_@\tSaved model to: \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/1_unfrozen_block/model/saved_model\"\n",
      "2024-03-29 14:35:32.216483: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 216 of 320\n",
      "2024-03-29 14:35:36.504774: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-03-29_1429/predict_sample.png\n",
      "2024-03-29 14:35:52.987079: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 227 of 320\n",
      "2024-03-29 14:35:56.648058: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x78424830da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0329 14:36:03.014176 132233308432192 polymorphic_function.py:154] 5 out of the last 5 calls to <function pfor.<locals>.f at 0x78424830da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x78424830da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0329 14:36:03.050422 132233308432192 polymorphic_function.py:154] 6 out of the last 6 calls to <function pfor.<locals>.f at 0x78424830da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "@_@\tResult of testing on 16 batches:\n",
      "@_@\t\tbinary_crossentropy: 0.5402472019195557\n",
      "@_@\t\tAUC: 0.6379052400588989\n",
      "@_@\t\tmacro_f1_score: 0.26793646812438965\n",
      "@_@\t\tsoft_f1_loss: 0.6967229843139648\n",
      "@_@\t\tglobal_accuracy: 0.7330728769302368\n",
      "@_@\t\tglobal_precision: 0.46760326623916626\n",
      "@_@\t\tglobal_recall: 0.5271410346031189\n",
      "@_@\t\n",
      "@_@\tDONE!\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "W0329 14:36:09.834649 132233308432192 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "W0329 14:36:09.834814 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "W0329 14:36:09.834884 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "W0329 14:36:09.834946 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "W0329 14:36:09.835006 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "W0329 14:36:09.835049 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "W0329 14:36:09.835094 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "W0329 14:36:09.835151 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "W0329 14:36:09.835181 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "W0329 14:36:09.835210 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "W0329 14:36:09.835239 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "W0329 14:36:09.835269 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "W0329 14:36:09.835298 132233308432192 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n"
     ]
    }
   ],
   "source": [
    "!python ../neural_nets/vgg16.py \\\n",
    "    --ouput_name=vgg16-test \\\n",
    "    --learning_rate=1e-5 --image_size=448 --epochs=20 --batch_size=32 --train_size=32 \\\n",
    "    --mode=train_then_eval --min_unfreeze_blocks=0 --max_unfreeze_blocks=1 \\\n",
    "    --load_checkpoint=./out/vgg16-gradual_2024-03-28_1652/1_unfrozen_block/model/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-13 20:59:59.046425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 20:59:59.616360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-13 21:00:00.738881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 21:00:00.777543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0313 21:00:01.402586 140455175722816 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "@_@\tStart: 2024-03-13_2100\n",
      "@_@\t\n",
      "@_@\tNumber of GPUs: 1\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 5000\n",
      "@_@\tEpochs: 10\n",
      "@_@\tBatch size per GPU: 16.0\n",
      "@_@\tOverall Batch size: 16\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\ttotal_size: 377110\n",
      "@_@\tsplit_size: {'train': 5000, 'validate': 741, 'test': 0}\n",
      "@_@\tsplit_size_frac: {'train': 0.013258730874280714, 'validate': 0.0019649439155684017, 'test': 0.0}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0313 21:00:49.186663 140455175722816 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [16, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [16, 7]\n",
      "2024-03-13 21:00:56.912094: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:00:56.912147: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-13 21:00:56.912232: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-13 21:00:57.014853: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:00:57.016042: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.396126 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.398212 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.399423 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.400036 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.402874 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.403472 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.404575 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.405161 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,856\n",
      "Trainable params: 40,438,855\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "2024-03-13 21:00:57.420339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 5000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0313 21:00:58.566590 140435578934848 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.683192 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.684458 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-03-13 21:01:08.604326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-13 21:01:14.519960: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fbc84005d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-13 21:01:14.520007: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-13 21:01:14.533653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-13 21:01:14.638154: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  4/313 [..............................] - ETA: 4:10 - loss: 0.8100 - macro_f1: 0.1200 - binary_crossentropy: 15.3029WARNING:tensorflow:Trace already enabled\n",
      "W0313 21:01:21.683152 140455175722816 summary_ops_v2.py:1325] Trace already enabled\n",
      "2024-03-13 21:01:21.683342: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:01:21.683382: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "  9/313 [..............................] - ETA: 11:20 - loss: 0.7634 - macro_f1: 0.1388 - binary_crossentropy: 8.00062024-03-13 21:01:40.024734: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2024-03-13 21:01:40.035891: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2024-03-13 21:01:40.116917: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 3235 callback api events and 3117 activity events. \n",
      "2024-03-13 21:01:40.142220: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:01:40.193099: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16_2024-03-13_2100/board/plugins/profile/2024_03_13_21_01_40/visionsw4.xplane.pb\n",
      "134/313 [===========>..................] - ETA: 9:16 - loss: 0.7574 - macro_f1: 0.0307 - binary_crossentropy: 1.0247^C\n"
     ]
    }
   ],
   "source": [
    "# Multi-GPU\n",
    "!python ../neural_nets/vgg16_mgpu.py \\\n",
    "    --ouput_name=vgg16 --gpu_mem_limit=10240 \\\n",
    "    --learning_rate=1e-3 --epochs=10 \\\n",
    "    --image_size=448 --batch_size=16 --train_size=5000 \\\n",
    "    --transfer_learning=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-27 03:06:45.056828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 03:06:45.581609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-27 03:06:45.581686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-27 03:06:45.581694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-27 03:06:46.608432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.642948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.643160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.643560: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 03:06:46.644442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.644645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.644802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\tCode version: 2\n",
      "@_@\tsubclassed + bce loss + large batch\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-03-27_0306\n",
      "@_@\t\n",
      "@_@\tMode: eval\n",
      "@_@\tUnfreeze blocks: 0\n",
      "@_@\tContinue from checkpoint: ./out_archive/vgg16-fixed-loss-memory/vgg16-all-frozen_2024-03-20_1758/model/checkpoints\n",
      "@_@\t\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 32\n",
      "@_@\tBatch size: 32\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tEpochs: 10\n",
      "@_@\tLearning Rate: 0.1\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tCPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 94539\n",
      "@_@\tsplit_size: {'train': 32, 'validate': 741, 'test': 500}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0327 03:07:31.249855 134224442926912 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [32, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [32, 7]\n",
      "2024-03-27 03:07:33.261423: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-27 03:07:33.261488: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-27 03:07:33.261609: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-27 03:07:33.406523: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-27 03:07:33.407752: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,855\n",
      "Trainable params: 25,724,167\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Total trainable weights: 6\n",
      "my_fc_1/kernel:0\n",
      "my_fc_1/bias:0\n",
      "my_fc_2/kernel:0\n",
      "my_fc_2/bias:0\n",
      "my_output/kernel:0\n",
      "my_output/bias:0\n",
      "2024-03-27 03:07:45.755973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 219 of 320\n",
      "2024-03-27 03:07:49.714532: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2024-03-27 03:07:52.494840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-eval_2024-03-27_0306/figs/predict_sample.png\n",
      "2024-03-27 03:08:15.531055: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 226 of 320\n",
      "2024-03-27 03:08:19.432564: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a11c45c5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0327 03:08:26.132805 134224442926912 polymorphic_function.py:154] 5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a11c45c5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a11c49ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0327 03:08:26.180053 134224442926912 polymorphic_function.py:154] 6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a11c49ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "total_samples <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=16>\n",
      "@_@\tbinary_crossentropy: 0.45600390434265137\n",
      "@_@\tAUC: 0.7501763701438904\n",
      "@_@\tmacro_f1_score: 0.33338695764541626\n",
      "@_@\tsoft_f1_loss: 0.6475182175636292\n",
      "@_@\tglobal_accuracy: 0.7714285254478455\n",
      "@_@\tglobal_precision: 0.5749470591545105\n",
      "@_@\tglobal_recall: 0.48433372378349304\n",
      "@_@\t\n",
      "@_@\tDONE!\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "W0327 03:08:37.932004 134224442926912 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "W0327 03:08:37.932121 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "W0327 03:08:37.932162 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "W0327 03:08:37.932197 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "W0327 03:08:37.932228 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "W0327 03:08:37.932259 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "W0327 03:08:37.932289 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "W0327 03:08:37.932318 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "W0327 03:08:37.932348 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "W0327 03:08:37.932377 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "W0327 03:08:37.932407 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "W0327 03:08:37.932437 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "W0327 03:08:37.932466 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    }
   ],
   "source": [
    "!python ../neural_nets/vgg16.py \\\n",
    "    --ouput_name=vgg16-eval \\\n",
    "    --image_size=448 --batch_size=32 --train_size=32 \\\n",
    "    --mode=eval --unfreeze_blocks=0 \\\n",
    "    --load_checkpoint=./out_archive/vgg16-fixed-loss-memory/vgg16-all-frozen_2024-03-20_1758/model/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-18 19:43:27.478057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 19:43:28.026217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-18 19:43:28.026324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-18 19:43:28.026332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-18 19:43:29.106692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.146669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.146856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.147203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 19:43:29.148312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.148460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.148587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.592620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.592839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.592995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 19:43:29.593120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\tCode version: 4\n",
      "@_@\tsubclassed + bce loss\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-03-18_1943\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 64\n",
      "@_@\tEpochs: 200\n",
      "@_@\tGlobal Batch size: 32\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\t\n",
      "@_@\tIs Transfer learning: True\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 94539\n",
      "@_@\tsplit_size: {'train': 64, 'validate': 0, 'test': 0}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0318 19:44:15.533369 140411098928960 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "2024-03-18 19:44:25.860098: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 57 of 64\n",
      "2024-03-18 19:44:26.911557: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "@_@\tShape of image batch: [32, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [32, 7]\n",
      "2024-03-18 19:44:28.337490: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-18 19:44:28.337505: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-18 19:44:28.337548: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-18 19:44:28.448918: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-18 19:44:28.450279: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,857\n",
      "Trainable params: 25,724,167\n",
      "Non-trainable params: 14,714,690\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0318 19:44:29.379021 140411098928960 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2024-03-18 19:44:40.952868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-18 19:44:50.648006: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55bf85311be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-18 19:44:50.648096: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-18 19:44:50.656895: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-18 19:44:50.784702: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2/2 [==============================] - 23s 412ms/step - loss: 2.1239 - macro_f1: 0.1455 - macro_soft_f1: 0.7982\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 2.5927 - macro_f1: 0.1443 - macro_soft_f1: 0.8627\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 1.5885 - macro_f1: 0.2689 - macro_soft_f1: 0.7264\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 1.2809 - macro_f1: 0.3479 - macro_soft_f1: 0.6685\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.8709 - macro_f1: 0.3920 - macro_soft_f1: 0.6227\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.4744 - macro_f1: 0.6552 - macro_soft_f1: 0.4286\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.2771 - macro_f1: 0.6913 - macro_soft_f1: 0.3520\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.4140 - macro_f1: 0.4189 - macro_soft_f1: 0.5497\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.1827 - macro_f1: 0.7213 - macro_soft_f1: 0.3035\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.1185 - macro_f1: 0.8743 - macro_soft_f1: 0.1660\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 12s 973ms/step - loss: 0.1313 - macro_f1: 0.8301 - macro_soft_f1: 0.2280\n",
      "Epoch 12/200\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.1576 - macro_f1: 0.7921 - macro_soft_f1: 0.2624WARNING:tensorflow:Trace already enabled\n",
      "W0318 19:47:00.498482 140411098928960 summary_ops_v2.py:1325] Trace already enabled\n",
      "2024-03-18 19:47:00.498640: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-18 19:47:00.498658: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.1341 - macro_f1: 0.8517 - macro_soft_f1: 0.2397\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0882 - macro_f1: 0.9242 - macro_soft_f1: 0.1697\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0674 - macro_f1: 0.9670 - macro_soft_f1: 0.0953\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0504 - macro_f1: 0.8056 - macro_soft_f1: 0.1485\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0503 - macro_f1: 0.8184 - macro_soft_f1: 0.1900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0302 - macro_f1: 0.9660 - macro_soft_f1: 0.0631\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0240 - macro_f1: 0.9921 - macro_soft_f1: 0.0370\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0185 - macro_f1: 1.0000 - macro_soft_f1: 0.0339\n",
      "Epoch 20/200\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0156 - macro_f1: 1.0000 - macro_soft_f1: 0.02762024-03-18 19:48:36.374285: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2024-03-18 19:48:36.379334: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2024-03-18 19:48:36.449257: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 6518 callback api events and 5821 activity events. \n",
      "2024-03-18 19:48:36.479617: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-18 19:48:36.567421: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-transfer-miniBatchTest_2024-03-18_1943/board/plugins/profile/2024_03_18_19_48_36/visionsw4.xplane.pb\n",
      "2/2 [==============================] - 13s 3s/step - loss: 0.0179 - macro_f1: 0.9958 - macro_soft_f1: 0.0318\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 12s 970ms/step - loss: 0.0176 - macro_f1: 0.9231 - macro_soft_f1: 0.1016\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0161 - macro_f1: 0.9286 - macro_soft_f1: 0.1109\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0135 - macro_f1: 0.9286 - macro_soft_f1: 0.0942\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0116 - macro_f1: 0.9286 - macro_soft_f1: 0.0948\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0102 - macro_f1: 1.0000 - macro_soft_f1: 0.0205\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0092 - macro_f1: 1.0000 - macro_soft_f1: 0.0189\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0082 - macro_f1: 1.0000 - macro_soft_f1: 0.0169\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0074 - macro_f1: 1.0000 - macro_soft_f1: 0.0129\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0071 - macro_f1: 1.0000 - macro_soft_f1: 0.0131\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0068 - macro_f1: 1.0000 - macro_soft_f1: 0.0116\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 12s 962ms/step - loss: 0.0064 - macro_f1: 1.0000 - macro_soft_f1: 0.0106\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0060 - macro_f1: 1.0000 - macro_soft_f1: 0.0105\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0057 - macro_f1: 1.0000 - macro_soft_f1: 0.0096\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0053 - macro_f1: 1.0000 - macro_soft_f1: 0.0091\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0052 - macro_f1: 1.0000 - macro_soft_f1: 0.0088\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0049 - macro_f1: 1.0000 - macro_soft_f1: 0.0083\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0048 - macro_f1: 1.0000 - macro_soft_f1: 0.0084\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0045 - macro_f1: 1.0000 - macro_soft_f1: 0.0079\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0044 - macro_f1: 1.0000 - macro_soft_f1: 0.0076\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0042 - macro_f1: 1.0000 - macro_soft_f1: 0.0070\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0041 - macro_f1: 0.9286 - macro_soft_f1: 0.0780\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0040 - macro_f1: 1.0000 - macro_soft_f1: 0.0070\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0039 - macro_f1: 1.0000 - macro_soft_f1: 0.0069\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0038 - macro_f1: 1.0000 - macro_soft_f1: 0.0063\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0037 - macro_f1: 1.0000 - macro_soft_f1: 0.0058\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0036 - macro_f1: 1.0000 - macro_soft_f1: 0.0059\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0035 - macro_f1: 1.0000 - macro_soft_f1: 0.0059\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0034 - macro_f1: 1.0000 - macro_soft_f1: 0.0056\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0033 - macro_f1: 1.0000 - macro_soft_f1: 0.0053\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0033 - macro_f1: 0.9286 - macro_soft_f1: 0.0766\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0032 - macro_f1: 0.9286 - macro_soft_f1: 0.0766\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0031 - macro_f1: 1.0000 - macro_soft_f1: 0.0067\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0031 - macro_f1: 1.0000 - macro_soft_f1: 0.0054\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0030 - macro_f1: 1.0000 - macro_soft_f1: 0.0051\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0029 - macro_f1: 1.0000 - macro_soft_f1: 0.0050\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0029 - macro_f1: 0.8571 - macro_soft_f1: 0.1473\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0028 - macro_f1: 1.0000 - macro_soft_f1: 0.0048\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0028 - macro_f1: 0.9286 - macro_soft_f1: 0.0759\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0027 - macro_f1: 0.9286 - macro_soft_f1: 0.0757\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0027 - macro_f1: 1.0000 - macro_soft_f1: 0.0045\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0026 - macro_f1: 1.0000 - macro_soft_f1: 0.0048\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0026 - macro_f1: 1.0000 - macro_soft_f1: 0.0044\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0025 - macro_f1: 1.0000 - macro_soft_f1: 0.0044\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0025 - macro_f1: 1.0000 - macro_soft_f1: 0.0045\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0024 - macro_f1: 0.9286 - macro_soft_f1: 0.0756\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.0024 - macro_f1: 1.0000 - macro_soft_f1: 0.0040\n",
      "Epoch 67/200\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/jupyter/../neural_nets/vgg16_test.py\", line 346, in <module>\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch Testing\n",
    "!python ../neural_nets/vgg16_test.py \\\n",
    "    --ouput_name=vgg16-transfer-miniBatchTest \\\n",
    "    --learning_rate=1e-3 --image_size=448 --epochs=200 --batch_size=32 --train_size=64 \\\n",
    "    --transfer_learning=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
