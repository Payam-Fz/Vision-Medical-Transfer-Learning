{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:18.467016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 19:37:19.140141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-11 19:37:19.140217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 19:37:19.933992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 19:37:19.971903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-04-02 19:57:02.789544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:57:03.309021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-04-02 19:57:03.309129: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-04-02 19:57:03.309137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-02 19:57:04.343334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.380449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.380662: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.381023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:57:04.381869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.382038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.382193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.816461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.816676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.816831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:57:04.816959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-04-02_1957\n",
      "@_@\t\n",
      "@_@\tMode: train_then_eval\n",
      "@_@\tUnfreeze blocks: start 0, end 2\n",
      "@_@\tContinue from checkpoint: False\n",
      "@_@\t\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 32\n",
      "@_@\tBatch size: 32\n",
      "@_@\tImage size: (224, 224)\n",
      "@_@\tMax Epochs per training round: 4\n",
      "@_@\tDefault Learning Rate: 0.1\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tCPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 9\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax' 'Fracture' 'Support Devices']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 112134\n",
      "@_@\tsplit_size: {'train': 32, 'validate': 889, 'test': 512}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0402 19:57:51.908224 124905014937408 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [32, 224, 224, 3]\n",
      "@_@\tShape of labels batch: [32, 9]\n",
      "Model: \"my_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " my_avg_pool (GlobalAverageP  (None, 512)              0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,880,073\n",
      "Trainable params: 165,385\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "@_@\t\n",
      "@_@\t------------------ Setup Round ------------------\n",
      "2024-04-02 19:57:54.387996: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-04-02 19:57:54.388065: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-04-02 19:57:54.388186: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-04-02 19:57:54.512256: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-04-02 19:57:54.513461: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "@_@\tUnfreezing 0 blocks...\n",
      "@_@\tTotal trainable weights: 6\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLearning rate = 0.001\n",
      "@_@\t\n",
      "@_@\t------------------ Training ------------------\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0402 19:57:54.950088 124905014937408 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2024-04-02 19:57:57.959111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-04-02 19:58:01.103985: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7197f8052570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-02 19:58:01.104044: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-04-02 19:58:01.108549: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-02 19:58:01.198869: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3090 - macro_f1_score: 0.2720 - soft_f1_loss: 0.7313 - AUC: 0.5453 - global_accuracy: 0.4931 - global_precision: 0.2562 - global_recall: 0.6029\n",
      "Epoch 1: val_loss improved from inf to 1.28911, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/checkpoints/epoch-01_valloss-1.2891.ckpt\n",
      "1/1 [==============================] - 51s 51s/step - loss: 3.3090 - macro_f1_score: 0.2720 - soft_f1_loss: 0.7313 - AUC: 0.5453 - global_accuracy: 0.4931 - global_precision: 0.2562 - global_recall: 0.6029 - val_loss: 1.2891 - val_macro_f1_score: 0.1532 - val_soft_f1_loss: 0.8310 - val_AUC: 0.4848 - val_global_accuracy: 0.6883 - val_global_precision: 0.3026 - val_global_recall: 0.2723\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1360 - macro_f1_score: 0.1604 - soft_f1_loss: 0.8077 - AUC: 0.6119 - global_accuracy: 0.7014 - global_precision: 0.3269 - global_recall: 0.2500\n",
      "Epoch 2: val_loss improved from 1.28911 to 1.20138, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/checkpoints/epoch-02_valloss-1.2014.ckpt\n",
      "1/1 [==============================] - 42s 42s/step - loss: 1.1360 - macro_f1_score: 0.1604 - soft_f1_loss: 0.8077 - AUC: 0.6119 - global_accuracy: 0.7014 - global_precision: 0.3269 - global_recall: 0.2500 - val_loss: 1.2014 - val_macro_f1_score: 0.1247 - val_soft_f1_loss: 0.8657 - val_AUC: 0.5046 - val_global_accuracy: 0.7568 - val_global_precision: 0.4472 - val_global_recall: 0.2329\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0559 - macro_f1_score: 0.1449 - soft_f1_loss: 0.8431 - AUC: 0.6119 - global_accuracy: 0.7674 - global_precision: 0.5152 - global_recall: 0.2500\n",
      "Epoch 3: val_loss improved from 1.20138 to 1.19709, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/checkpoints/epoch-03_valloss-1.1971.ckpt\n",
      "1/1 [==============================] - 42s 42s/step - loss: 1.0559 - macro_f1_score: 0.1449 - soft_f1_loss: 0.8431 - AUC: 0.6119 - global_accuracy: 0.7674 - global_precision: 0.5152 - global_recall: 0.2500 - val_loss: 1.1971 - val_macro_f1_score: 0.1452 - val_soft_f1_loss: 0.8343 - val_AUC: 0.5023 - val_global_accuracy: 0.7475 - val_global_precision: 0.4392 - val_global_recall: 0.3415\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9465 - macro_f1_score: 0.2984 - soft_f1_loss: 0.7410 - AUC: 0.6514 - global_accuracy: 0.7917 - global_precision: 0.5714 - global_recall: 0.4706\n",
      "Epoch 4: val_loss did not improve from 1.19709\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.9465 - macro_f1_score: 0.2984 - soft_f1_loss: 0.7410 - AUC: 0.6514 - global_accuracy: 0.7917 - global_precision: 0.5714 - global_recall: 0.4706 - val_loss: 1.2079 - val_macro_f1_score: 0.1835 - val_soft_f1_loss: 0.8090 - val_AUC: 0.5042 - val_global_accuracy: 0.7276 - val_global_precision: 0.4107 - val_global_recall: 0.4253\n",
      "@_@\t\n",
      "@_@\t------------------ Training Round Summary ------------------\n",
      "@_@\tTraining took 0h:2m:56s\n",
      "@_@\thistory of metrics:\n",
      "@_@\t\tloss: [3.308957099914551, 1.135993242263794, 1.0559113025665283, 0.9465117454528809]\n",
      "@_@\t\tmacro_f1_score: [0.27195581793785095, 0.16044741868972778, 0.144871786236763, 0.2984181046485901]\n",
      "@_@\t\tsoft_f1_loss: [0.7312623262405396, 0.8076833486557007, 0.8431187272071838, 0.7410406470298767]\n",
      "@_@\t\tAUC: [0.5453458428382874, 0.6119238138198853, 0.6118962168693542, 0.6514155864715576]\n",
      "@_@\t\tglobal_accuracy: [0.4930555522441864, 0.7013888955116272, 0.7673611044883728, 0.7916666865348816]\n",
      "@_@\t\tglobal_precision: [0.2562499940395355, 0.32692307233810425, 0.5151515007019043, 0.5714285969734192]\n",
      "@_@\t\tglobal_recall: [0.6029411554336548, 0.25, 0.25, 0.47058823704719543]\n",
      "@_@\t\tval_loss: [1.2891149520874023, 1.2013835906982422, 1.1970871686935425, 1.2079427242279053]\n",
      "@_@\t\tval_macro_f1_score: [0.15324212610721588, 0.12466897815465927, 0.14515776932239532, 0.18350397050380707]\n",
      "@_@\t\tval_soft_f1_loss: [0.8309835195541382, 0.8656944036483765, 0.8343116641044617, 0.8089689016342163]\n",
      "@_@\t\tval_AUC: [0.48475509881973267, 0.5045960545539856, 0.5023183226585388, 0.5041614770889282]\n",
      "@_@\t\tval_global_accuracy: [0.6883134841918945, 0.7567558884620667, 0.7474899291992188, 0.7276040315628052]\n",
      "@_@\t\tval_global_precision: [0.3025631010532379, 0.447160929441452, 0.4391537606716156, 0.41069746017456055]\n",
      "@_@\t\tval_global_recall: [0.27231565117836, 0.23294255137443542, 0.3414507508277893, 0.4253441393375397]\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/figs/learning_curve.png\n",
      "@_@\tValidation loss: 1.2079\n",
      "@_@\tValidation Macro F1-score: 0.1835\n",
      "W0402 20:00:52.277148 124905014937408 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/saved_model/assets\n",
      "I0402 20:00:53.914640 124905014937408 builder_impl.py:797] Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/saved_model/assets\n",
      "@_@\tSaved model to: \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/saved_model\"\n",
      "@_@\t\n",
      "@_@\t------------------ Setup Round ------------------\n",
      "2024-04-02 20:00:54.168701: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-04-02 20:00:54.168774: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-04-02 20:00:54.393305: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-04-02 20:00:54.395967: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "@_@\tUnfreezing 1 blocks...\n",
      "@_@\tTotal trainable weights: 12\n",
      "@_@\t\tblock5_conv1/kernel:0\n",
      "@_@\t\tblock5_conv1/bias:0\n",
      "@_@\t\tblock5_conv2/kernel:0\n",
      "@_@\t\tblock5_conv2/bias:0\n",
      "@_@\t\tblock5_conv3/kernel:0\n",
      "@_@\t\tblock5_conv3/bias:0\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLearning rate = 1e-05\n",
      "@_@\tLoading weights from /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/0_unfrozen_block/model/checkpoints/epoch-03_valloss-1.1971.ckpt\n",
      "@_@\t\n",
      "@_@\t------------------ Training ------------------\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9623 - macro_f1_score: 0.3004 - soft_f1_loss: 0.7382 - AUC: 0.6534 - global_accuracy: 0.7847 - global_precision: 0.5500 - global_recall: 0.4853\n",
      "Epoch 1: val_loss improved from inf to 2.51949, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/checkpoints/epoch-01_valloss-2.5195.ckpt\n",
      "1/1 [==============================] - 46s 46s/step - loss: 0.9623 - macro_f1_score: 0.3004 - soft_f1_loss: 0.7382 - AUC: 0.6534 - global_accuracy: 0.7847 - global_precision: 0.5500 - global_recall: 0.4853 - val_loss: 2.5195 - val_macro_f1_score: 0.1859 - val_soft_f1_loss: 0.8057 - val_AUC: 0.4951 - val_global_accuracy: 0.4662 - val_global_precision: 0.2088 - val_global_recall: 0.4723\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7251 - macro_f1_score: 0.1869 - soft_f1_loss: 0.7850 - AUC: 0.4826 - global_accuracy: 0.4444 - global_precision: 0.1974 - global_recall: 0.4412\n",
      "Epoch 2: val_loss improved from 2.51949 to 0.90901, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/checkpoints/epoch-02_valloss-0.9090.ckpt\n",
      "1/1 [==============================] - 43s 43s/step - loss: 2.7251 - macro_f1_score: 0.1869 - soft_f1_loss: 0.7850 - AUC: 0.4826 - global_accuracy: 0.4444 - global_precision: 0.1974 - global_recall: 0.4412 - val_loss: 0.9090 - val_macro_f1_score: 0.1989 - val_soft_f1_loss: 0.7635 - val_AUC: 0.4800 - val_global_accuracy: 0.6282 - val_global_precision: 0.2968 - val_global_recall: 0.4476\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9227 - macro_f1_score: 0.2394 - soft_f1_loss: 0.7274 - AUC: 0.5409 - global_accuracy: 0.6389 - global_precision: 0.3333 - global_recall: 0.5294\n",
      "Epoch 3: val_loss did not improve from 0.90901\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.9227 - macro_f1_score: 0.2394 - soft_f1_loss: 0.7274 - AUC: 0.5409 - global_accuracy: 0.6389 - global_precision: 0.3333 - global_recall: 0.5294 - val_loss: 1.0735 - val_macro_f1_score: 0.2332 - val_soft_f1_loss: 0.7506 - val_AUC: 0.5065 - val_global_accuracy: 0.6501 - val_global_precision: 0.3587 - val_global_recall: 0.6610\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0314 - macro_f1_score: 0.2719 - soft_f1_loss: 0.7291 - AUC: 0.5220 - global_accuracy: 0.6597 - global_precision: 0.3729 - global_recall: 0.6471\n",
      "Epoch 4: val_loss improved from 0.90901 to 0.63373, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/checkpoints/epoch-04_valloss-0.6337.ckpt\n",
      "1/1 [==============================] - 43s 43s/step - loss: 1.0314 - macro_f1_score: 0.2719 - soft_f1_loss: 0.7291 - AUC: 0.5220 - global_accuracy: 0.6597 - global_precision: 0.3729 - global_recall: 0.6471 - val_loss: 0.6337 - val_macro_f1_score: 0.2123 - val_soft_f1_loss: 0.7682 - val_AUC: 0.5480 - val_global_accuracy: 0.6698 - val_global_precision: 0.3429 - val_global_recall: 0.4691\n",
      "@_@\t\n",
      "@_@\t------------------ Training Round Summary ------------------\n",
      "@_@\tTraining took 0h:2m:52s\n",
      "@_@\thistory of metrics:\n",
      "@_@\t\tloss: [0.962279200553894, 2.72514009475708, 0.9226775169372559, 1.0314466953277588]\n",
      "@_@\t\tmacro_f1_score: [0.3004149794578552, 0.18688219785690308, 0.23935696482658386, 0.2719193398952484]\n",
      "@_@\t\tsoft_f1_loss: [0.7382147908210754, 0.7849661111831665, 0.7273680567741394, 0.7290546298027039]\n",
      "@_@\t\tAUC: [0.6534436941146851, 0.4826124608516693, 0.5409482717514038, 0.5220029354095459]\n",
      "@_@\t\tglobal_accuracy: [0.7847222089767456, 0.4444444477558136, 0.6388888955116272, 0.6597222089767456]\n",
      "@_@\t\tglobal_precision: [0.550000011920929, 0.19736842811107635, 0.3333333432674408, 0.37288135290145874]\n",
      "@_@\t\tglobal_recall: [0.4852941036224365, 0.44117647409439087, 0.529411792755127, 0.6470588445663452]\n",
      "@_@\t\tval_loss: [2.5194928646087646, 0.9090107679367065, 1.0734575986862183, 0.6337306499481201]\n",
      "@_@\t\tval_macro_f1_score: [0.18592388927936554, 0.19892676174640656, 0.23317977786064148, 0.21230103075504303]\n",
      "@_@\t\tval_soft_f1_loss: [0.8056976199150085, 0.7635067701339722, 0.7505725026130676, 0.7681609988212585]\n",
      "@_@\t\tval_AUC: [0.4950864613056183, 0.4799793064594269, 0.506514310836792, 0.5479893684387207]\n",
      "@_@\t\tval_global_accuracy: [0.46615079045295715, 0.6282142400741577, 0.6500644683837891, 0.669786810874939]\n",
      "@_@\t\tval_global_precision: [0.2087843418121338, 0.29677391052246094, 0.35874250531196594, 0.34287533164024353]\n",
      "@_@\t\tval_global_recall: [0.4723223149776459, 0.4476185441017151, 0.6610393524169922, 0.4690883755683899]\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/figs/learning_curve.png\n",
      "@_@\tValidation loss: 0.6337\n",
      "@_@\tValidation Macro F1-score: 0.2123\n",
      "W0402 20:03:48.182852 124905014937408 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/saved_model/assets\n",
      "I0402 20:03:51.016282 124905014937408 builder_impl.py:797] Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/saved_model/assets\n",
      "@_@\tSaved model to: \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/saved_model\"\n",
      "@_@\t\n",
      "@_@\t------------------ Setup Round ------------------\n",
      "2024-04-02 20:03:51.237367: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-04-02 20:03:51.237418: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-04-02 20:03:51.420957: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-04-02 20:03:51.425977: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "@_@\tUnfreezing 2 blocks...\n",
      "@_@\tTotal trainable weights: 18\n",
      "@_@\t\tblock4_conv1/kernel:0\n",
      "@_@\t\tblock4_conv1/bias:0\n",
      "@_@\t\tblock4_conv2/kernel:0\n",
      "@_@\t\tblock4_conv2/bias:0\n",
      "@_@\t\tblock4_conv3/kernel:0\n",
      "@_@\t\tblock4_conv3/bias:0\n",
      "@_@\t\tblock5_conv1/kernel:0\n",
      "@_@\t\tblock5_conv1/bias:0\n",
      "@_@\t\tblock5_conv2/kernel:0\n",
      "@_@\t\tblock5_conv2/bias:0\n",
      "@_@\t\tblock5_conv3/kernel:0\n",
      "@_@\t\tblock5_conv3/bias:0\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLearning rate = 1e-05\n",
      "@_@\tLoading weights from /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/1_unfrozen_block/model/checkpoints/epoch-04_valloss-0.6337.ckpt\n",
      "@_@\t\n",
      "@_@\t------------------ Training ------------------\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6673 - macro_f1_score: 0.2038 - soft_f1_loss: 0.7584 - AUC: 0.5359 - global_accuracy: 0.6597 - global_precision: 0.3333 - global_recall: 0.4412\n",
      "Epoch 1: val_loss improved from inf to 6.74407, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/checkpoints/epoch-01_valloss-6.7441.ckpt\n",
      "1/1 [==============================] - 48s 48s/step - loss: 0.6673 - macro_f1_score: 0.2038 - soft_f1_loss: 0.7584 - AUC: 0.5359 - global_accuracy: 0.6597 - global_precision: 0.3333 - global_recall: 0.4412 - val_loss: 6.7441 - val_macro_f1_score: 0.1917 - val_soft_f1_loss: 0.8132 - val_AUC: 0.4943 - val_global_accuracy: 0.5925 - val_global_precision: 0.2943 - val_global_recall: 0.5521\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8960 - macro_f1_score: 0.1894 - soft_f1_loss: 0.8120 - AUC: 0.4794 - global_accuracy: 0.5799 - global_precision: 0.2880 - global_recall: 0.5294\n",
      "Epoch 2: val_loss improved from 6.74407 to 1.59483, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/checkpoints/epoch-02_valloss-1.5948.ckpt\n",
      "1/1 [==============================] - 44s 44s/step - loss: 6.8960 - macro_f1_score: 0.1894 - soft_f1_loss: 0.8120 - AUC: 0.4794 - global_accuracy: 0.5799 - global_precision: 0.2880 - global_recall: 0.5294 - val_loss: 1.5948 - val_macro_f1_score: 0.1331 - val_soft_f1_loss: 0.8319 - val_AUC: 0.4916 - val_global_accuracy: 0.7439 - val_global_precision: 0.4413 - val_global_recall: 0.4265\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7119 - macro_f1_score: 0.1351 - soft_f1_loss: 0.8306 - AUC: 0.4598 - global_accuracy: 0.7361 - global_precision: 0.4375 - global_recall: 0.4118\n",
      "Epoch 3: val_loss improved from 1.59483 to 0.65981, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/checkpoints/epoch-03_valloss-0.6598.ckpt\n",
      "1/1 [==============================] - 43s 43s/step - loss: 1.7119 - macro_f1_score: 0.1351 - soft_f1_loss: 0.8306 - AUC: 0.4598 - global_accuracy: 0.7361 - global_precision: 0.4375 - global_recall: 0.4118 - val_loss: 0.6598 - val_macro_f1_score: 0.0706 - val_soft_f1_loss: 0.8442 - val_AUC: 0.5057 - val_global_accuracy: 0.7763 - val_global_precision: 0.5379 - val_global_recall: 0.2116\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7037 - macro_f1_score: 0.0667 - soft_f1_loss: 0.8403 - AUC: 0.5009 - global_accuracy: 0.7604 - global_precision: 0.4800 - global_recall: 0.1765\n",
      "Epoch 4: val_loss improved from 0.65981 to 0.55834, saving model to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/checkpoints/epoch-04_valloss-0.5583.ckpt\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.7037 - macro_f1_score: 0.0667 - soft_f1_loss: 0.8403 - AUC: 0.5009 - global_accuracy: 0.7604 - global_precision: 0.4800 - global_recall: 0.1765 - val_loss: 0.5583 - val_macro_f1_score: 0.0981 - val_soft_f1_loss: 0.7415 - val_AUC: 0.4994 - val_global_accuracy: 0.7699 - val_global_precision: 0.5018 - val_global_recall: 0.2618\n",
      "@_@\t\n",
      "@_@\t------------------ Training Round Summary ------------------\n",
      "@_@\tTraining took 0h:2m:59s\n",
      "@_@\thistory of metrics:\n",
      "@_@\t\tloss: [0.6672849059104919, 6.895961284637451, 1.7118518352508545, 0.703657865524292]\n",
      "@_@\t\tmacro_f1_score: [0.2038416713476181, 0.18941126763820648, 0.1351195126771927, 0.06666667014360428]\n",
      "@_@\t\tsoft_f1_loss: [0.7584138512611389, 0.8120049834251404, 0.8306402564048767, 0.8403144478797913]\n",
      "@_@\t\tAUC: [0.5358874201774597, 0.47940096259117126, 0.45979514718055725, 0.5008987188339233]\n",
      "@_@\t\tglobal_accuracy: [0.6597222089767456, 0.5798611044883728, 0.7361111044883728, 0.7604166865348816]\n",
      "@_@\t\tglobal_precision: [0.3333333432674408, 0.2879999876022339, 0.4375, 0.47999998927116394]\n",
      "@_@\t\tglobal_recall: [0.44117647409439087, 0.529411792755127, 0.4117647111415863, 0.1764705926179886]\n",
      "@_@\t\tval_loss: [6.74406623840332, 1.5948314666748047, 0.6598060131072998, 0.5583357214927673]\n",
      "@_@\t\tval_macro_f1_score: [0.19171062111854553, 0.1330689936876297, 0.070587657392025, 0.09814952313899994]\n",
      "@_@\t\tval_soft_f1_loss: [0.8132473230361938, 0.8318634033203125, 0.8442384004592896, 0.7415080070495605]\n",
      "@_@\t\tval_AUC: [0.49426671862602234, 0.4915579557418823, 0.5056674480438232, 0.4994302988052368]\n",
      "@_@\t\tval_global_accuracy: [0.5925248265266418, 0.7438839077949524, 0.7763292193412781, 0.7699156403541565]\n",
      "@_@\t\tval_global_precision: [0.29433488845825195, 0.4412723183631897, 0.5379027128219604, 0.5017640590667725]\n",
      "@_@\t\tval_global_recall: [0.5520968437194824, 0.4264703691005707, 0.21160447597503662, 0.26183339953422546]\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/figs/learning_curve.png\n",
      "@_@\tValidation loss: 0.5583\n",
      "@_@\tValidation Macro F1-score: 0.0981\n",
      "W0402 20:06:53.100597 124905014937408 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/saved_model/assets\n",
      "I0402 20:06:56.887480 124905014937408 builder_impl.py:797] Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/saved_model/assets\n",
      "@_@\tSaved model to: \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/2_unfrozen_block/model/saved_model\"\n",
      "@_@\t\n",
      "@_@\t------------------ Evaluate ------------------\n",
      "2024-04-02 20:07:07.130393: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 214 of 320\n",
      "2024-04-02 20:07:11.499038: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-test_2024-04-02_1957/predict_sample.png\n",
      "2024-04-02 20:07:27.459015: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 229 of 320\n",
      "2024-04-02 20:07:31.382763: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7197c655e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0402 20:07:36.611108 124905014937408 polymorphic_function.py:154] 5 out of the last 5 calls to <function pfor.<locals>.f at 0x7197c655e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7197c655e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0402 20:07:37.160911 124905014937408 polymorphic_function.py:154] 6 out of the last 6 calls to <function pfor.<locals>.f at 0x7197c655e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "@_@\tResult of testing on 16 batches:\n",
      "@_@\t\tbinary_crossentropy: 0.5787568092346191\n",
      "@_@\t\tAUC: 0.49721792340278625\n",
      "@_@\t\tmacro_f1_score: 0.0916038304567337\n",
      "@_@\t\tsoft_f1_loss: 0.7246383428573608\n",
      "@_@\t\tglobal_accuracy: 0.7387152314186096\n",
      "@_@\t\tglobal_precision: 0.45080670714378357\n",
      "@_@\t\tglobal_recall: 0.22340650856494904\n",
      "@_@\t\n",
      "@_@\tDONE!\n"
     ]
    }
   ],
   "source": [
    "!python ../neural_nets/vgg16.py \\\n",
    "    --ouput_name=vgg16-test \\\n",
    "    --image_size=224 --epochs=4 --batch_size=32 --train_size=32 \\\n",
    "    --mode=train_then_eval --min_unfreeze_blocks=0 --max_unfreeze_blocks=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-13 20:59:59.046425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 20:59:59.616360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-13 20:59:59.616449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-13 21:00:00.738881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.776665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 21:00:00.777543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:00.777888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-13 21:00:01.245845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0313 21:00:01.402586 140455175722816 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "@_@\tStart: 2024-03-13_2100\n",
      "@_@\t\n",
      "@_@\tNumber of GPUs: 1\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 5000\n",
      "@_@\tEpochs: 10\n",
      "@_@\tBatch size per GPU: 16.0\n",
      "@_@\tOverall Batch size: 16\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\ttotal_size: 377110\n",
      "@_@\tsplit_size: {'train': 5000, 'validate': 741, 'test': 0}\n",
      "@_@\tsplit_size_frac: {'train': 0.013258730874280714, 'validate': 0.0019649439155684017, 'test': 0.0}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0313 21:00:49.186663 140455175722816 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [16, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [16, 7]\n",
      "2024-03-13 21:00:56.912094: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:00:56.912147: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-13 21:00:56.912232: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-13 21:00:57.014853: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:00:57.016042: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.396126 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.398212 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.399423 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.400036 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.402874 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.403472 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.404575 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:57.405161 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,856\n",
      "Trainable params: 40,438,855\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n",
      "2024-03-13 21:00:57.420339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 5000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0313 21:00:58.566590 140435578934848 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.683192 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0313 21:00:58.684458 140455175722816 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-03-13 21:01:08.604326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-03-13 21:01:14.519960: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fbc84005d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-13 21:01:14.520007: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-03-13 21:01:14.533653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-13 21:01:14.638154: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  4/313 [..............................] - ETA: 4:10 - loss: 0.8100 - macro_f1: 0.1200 - binary_crossentropy: 15.3029WARNING:tensorflow:Trace already enabled\n",
      "W0313 21:01:21.683152 140455175722816 summary_ops_v2.py:1325] Trace already enabled\n",
      "2024-03-13 21:01:21.683342: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-13 21:01:21.683382: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "  9/313 [..............................] - ETA: 11:20 - loss: 0.7634 - macro_f1: 0.1388 - binary_crossentropy: 8.00062024-03-13 21:01:40.024734: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2024-03-13 21:01:40.035891: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2024-03-13 21:01:40.116917: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 3235 callback api events and 3117 activity events. \n",
      "2024-03-13 21:01:40.142220: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-13 21:01:40.193099: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16_2024-03-13_2100/board/plugins/profile/2024_03_13_21_01_40/visionsw4.xplane.pb\n",
      "134/313 [===========>..................] - ETA: 9:16 - loss: 0.7574 - macro_f1: 0.0307 - binary_crossentropy: 1.0247^C\n"
     ]
    }
   ],
   "source": [
    "# Multi-GPU\n",
    "!python ../neural_nets/vgg16_mgpu.py \\\n",
    "    --ouput_name=vgg16 --gpu_mem_limit=10240 \\\n",
    "    --learning_rate=1e-3 --epochs=10 \\\n",
    "    --image_size=448 --batch_size=16 --train_size=5000 \\\n",
    "    --transfer_learning=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:17:34.986949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 10:17:35.786915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64\n",
      "2024-04-09 10:17:35.787001: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64\n",
      "2024-04-09 10:17:35.787007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-09 10:17:37.667594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-09 10:17:37.726875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64\n",
      "2024-04-09 10:17:37.726899: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:14:13.680798: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 10:14:14.583700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64\n",
      "2024-04-09 10:14:14.583768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64\n",
      "2024-04-09 10:14:14.583779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-09 10:14:16.330778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-09 10:14:16.390816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64\n",
      "2024-04-09 10:14:16.390855: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "GPU LIST: []\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tensorflow as tf; print('GPU LIST:', tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-03-27 03:06:45.056828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 03:06:45.581609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-27 03:06:45.581686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-03-27 03:06:45.581694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-27 03:06:46.608432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.642948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.643160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.643560: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 03:06:46.644442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.644645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:46.644802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-27 03:06:47.079761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\tCode version: 2\n",
      "@_@\tsubclassed + bce loss + large batch\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-03-27_0306\n",
      "@_@\t\n",
      "@_@\tMode: eval\n",
      "@_@\tUnfreeze blocks: 0\n",
      "@_@\tContinue from checkpoint: ./out_archive/vgg16-fixed-loss-memory/vgg16-all-frozen_2024-03-20_1758/model/checkpoints\n",
      "@_@\t\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 32\n",
      "@_@\tBatch size: 32\n",
      "@_@\tImage size: (448, 448)\n",
      "@_@\tEpochs: 10\n",
      "@_@\tLearning Rate: 0.1\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tCPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 7\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 94539\n",
      "@_@\tsplit_size: {'train': 32, 'validate': 741, 'test': 500}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0327 03:07:31.249855 134224442926912 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [32, 448, 448, 3]\n",
      "@_@\tShape of labels batch: [32, 7]\n",
      "2024-03-27 03:07:33.261423: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2024-03-27 03:07:33.261488: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2024-03-27 03:07:33.261609: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2024-03-27 03:07:33.406523: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2024-03-27 03:07:33.407752: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "Model: \"base_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               25690368  \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,438,855\n",
      "Trainable params: 25,724,167\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Total trainable weights: 6\n",
      "my_fc_1/kernel:0\n",
      "my_fc_1/bias:0\n",
      "my_fc_2/kernel:0\n",
      "my_fc_2/bias:0\n",
      "my_output/kernel:0\n",
      "my_output/bias:0\n",
      "2024-03-27 03:07:45.755973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 219 of 320\n",
      "2024-03-27 03:07:49.714532: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2024-03-27 03:07:52.494840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-eval_2024-03-27_0306/figs/predict_sample.png\n",
      "2024-03-27 03:08:15.531055: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 226 of 320\n",
      "2024-03-27 03:08:19.432564: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a11c45c5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0327 03:08:26.132805 134224442926912 polymorphic_function.py:154] 5 out of the last 5 calls to <function pfor.<locals>.f at 0x7a11c45c5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a11c49ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0327 03:08:26.180053 134224442926912 polymorphic_function.py:154] 6 out of the last 6 calls to <function pfor.<locals>.f at 0x7a11c49ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "total_samples <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=16>\n",
      "@_@\tbinary_crossentropy: 0.45600390434265137\n",
      "@_@\tAUC: 0.7501763701438904\n",
      "@_@\tmacro_f1_score: 0.33338695764541626\n",
      "@_@\tsoft_f1_loss: 0.6475182175636292\n",
      "@_@\tglobal_accuracy: 0.7714285254478455\n",
      "@_@\tglobal_precision: 0.5749470591545105\n",
      "@_@\tglobal_recall: 0.48433372378349304\n",
      "@_@\t\n",
      "@_@\tDONE!\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "W0327 03:08:37.932004 134224442926912 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "W0327 03:08:37.932121 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "W0327 03:08:37.932162 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "W0327 03:08:37.932197 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "W0327 03:08:37.932228 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "W0327 03:08:37.932259 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "W0327 03:08:37.932289 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "W0327 03:08:37.932318 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "W0327 03:08:37.932348 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "W0327 03:08:37.932377 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "W0327 03:08:37.932407 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "W0327 03:08:37.932437 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "W0327 03:08:37.932466 134224442926912 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    }
   ],
   "source": [
    "!python ../neural_nets/vgg16.py \\\n",
    "    --ouput_name=vgg16-eval \\\n",
    "    --image_size=448 --batch_size=32 --train_size=32 \\\n",
    "    --mode=eval --unfreeze_blocks=0 \\\n",
    "    --load_checkpoint=./out_archive/vgg16-fixed-loss-memory/vgg16-all-frozen_2024-03-20_1758/model/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cwd to '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation'\n",
      "['/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/neural_nets', '/home/payam/miniconda3/envs/tf2-gpu/lib/python39.zip', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/lib-dynload', '/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages', '/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode']\n",
      "/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation\n",
      "2024-04-02 19:52:31.961882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:52:32.478945: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-04-02 19:52:32.479038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-04-02 19:52:32.479046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-02 19:52:33.488669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.525986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.526200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.526561: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:52:33.527336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.527531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.527716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.960235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.960453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.960625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-02 19:52:33.960800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "@_@\t\n",
      "@_@\t------------------ Configuration ------------------\n",
      "@_@\tStart: 2024-04-02_1952\n",
      "@_@\t\n",
      "@_@\tMode: train_then_eval\n",
      "@_@\tUnfreeze blocks: start 0, end 3\n",
      "@_@\tContinue from checkpoint: False\n",
      "@_@\t\n",
      "@_@\tDataset: MIMIC-CXR\n",
      "@_@\tTraining Dataset Size: 8\n",
      "@_@\tBatch size: 8\n",
      "@_@\tImage size: (224, 224)\n",
      "@_@\tMax Epochs per training round: 100\n",
      "@_@\tDefault Learning Rate: 0.1\n",
      "@_@\t\n",
      "@_@\tGPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "@_@\tCPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "@_@\t\n",
      "@_@\t------------------ Data ------------------\n",
      "@_@\tnum_classes: 9\n",
      "@_@\tclass_names: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Pleural Effusion'\n",
      "@_@\t 'Pneumonia' 'Pneumothorax' 'Fracture' 'Support Devices']\n",
      "@_@\tall_data_size: 377110\n",
      "@_@\tall_data_filtered_size: 112134\n",
      "@_@\tsplit_size: {'train': 8, 'validate': 889, 'test': 512}\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0402 19:53:21.499979 129459121858368 deprecation.py:350] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "@_@\tShape of image batch: [8, 224, 224, 3]\n",
      "@_@\tShape of labels batch: [8, 9]\n",
      "Model: \"my_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " my_avg_pool (GlobalAverageP  (None, 512)              0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " my_fc_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " my_fc_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " my_output (Dense)           (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,880,073\n",
      "Trainable params: 165,385\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "@_@\t\n",
      "@_@\t------------------ Setup Round ------------------\n",
      "@_@\tUnfreezing 0 blocks...\n",
      "@_@\tTotal trainable weights: 6\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLearning rate = 0.001\n",
      "@_@\t\n",
      "@_@\t------------------ Training ------------------\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0402 19:53:23.010661 129459121858368 deprecation.py:554] From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2024-04-02 19:53:24.993735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-04-02 19:53:26.171852: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x75bc180b4570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-02 19:53:26.171877: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-04-02 19:53:26.178106: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-02 19:53:26.265329: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "1/1 [==============================] - 5s 5s/step - loss: 2.0252 - macro_f1_score: 0.2654 - soft_f1_loss: 0.7206 - AUC: 0.5246 - global_accuracy: 0.5417 - global_precision: 0.2857 - global_recall: 0.3810 - val_loss: 1.0589 - val_macro_f1_score: 0.2019 - val_soft_f1_loss: 0.7240 - val_AUC: 0.6706 - val_global_accuracy: 0.7083 - val_global_precision: 0.5000 - val_global_recall: 0.3810\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 1.0589 - macro_f1_score: 0.2019 - soft_f1_loss: 0.7240 - AUC: 0.6706 - global_accuracy: 0.7083 - global_precision: 0.5000 - global_recall: 0.3810 - val_loss: 0.5619 - val_macro_f1_score: 0.3951 - val_soft_f1_loss: 0.5658 - val_AUC: 0.7681 - val_global_accuracy: 0.8333 - val_global_precision: 0.8462 - val_global_recall: 0.5238\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5619 - macro_f1_score: 0.3951 - soft_f1_loss: 0.5658 - AUC: 0.7681 - global_accuracy: 0.8333 - global_precision: 0.8462 - global_recall: 0.5238 - val_loss: 0.4290 - val_macro_f1_score: 0.7104 - val_soft_f1_loss: 0.3796 - val_AUC: 0.8333 - val_global_accuracy: 0.9306 - val_global_precision: 0.8636 - val_global_recall: 0.9048\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.4290 - macro_f1_score: 0.7104 - soft_f1_loss: 0.3796 - AUC: 0.8333 - global_accuracy: 0.9306 - global_precision: 0.8636 - global_recall: 0.9048 - val_loss: 0.3516 - val_macro_f1_score: 0.7475 - val_soft_f1_loss: 0.3093 - val_AUC: 0.8333 - val_global_accuracy: 0.9444 - val_global_precision: 0.8696 - val_global_recall: 0.9524\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.3516 - macro_f1_score: 0.7475 - soft_f1_loss: 0.3093 - AUC: 0.8333 - global_accuracy: 0.9444 - global_precision: 0.8696 - global_recall: 0.9524 - val_loss: 0.1945 - val_macro_f1_score: 0.7333 - val_soft_f1_loss: 0.2954 - val_AUC: 0.8333 - val_global_accuracy: 0.9444 - val_global_precision: 0.9048 - val_global_recall: 0.9048\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1945 - macro_f1_score: 0.7333 - soft_f1_loss: 0.2954 - AUC: 0.8333 - global_accuracy: 0.9444 - global_precision: 0.9048 - global_recall: 0.9048 - val_loss: 0.1445 - val_macro_f1_score: 0.7333 - val_soft_f1_loss: 0.2944 - val_AUC: 0.8333 - val_global_accuracy: 0.9583 - val_global_precision: 0.9500 - val_global_recall: 0.9048\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1445 - macro_f1_score: 0.7333 - soft_f1_loss: 0.2944 - AUC: 0.8333 - global_accuracy: 0.9583 - global_precision: 0.9500 - global_recall: 0.9048 - val_loss: 0.1197 - val_macro_f1_score: 0.7175 - val_soft_f1_loss: 0.2835 - val_AUC: 0.8889 - val_global_accuracy: 0.9444 - val_global_precision: 0.9474 - val_global_recall: 0.8571\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1197 - macro_f1_score: 0.7175 - soft_f1_loss: 0.2835 - AUC: 0.8889 - global_accuracy: 0.9444 - global_precision: 0.9474 - global_recall: 0.8571 - val_loss: 0.0662 - val_macro_f1_score: 0.8508 - val_soft_f1_loss: 0.1850 - val_AUC: 0.8889 - val_global_accuracy: 0.9722 - val_global_precision: 0.9524 - val_global_recall: 0.9524\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.0662 - macro_f1_score: 0.8508 - soft_f1_loss: 0.1850 - AUC: 0.8889 - global_accuracy: 0.9722 - global_precision: 0.9524 - global_recall: 0.9524 - val_loss: 0.0253 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1445 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0253 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1445 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0154 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1297 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0154 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1297 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0121 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1252 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0121 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1252 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0084 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1222 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0084 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1222 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0072 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1219 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 993ms/step - loss: 0.0072 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1219 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0078 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1236 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.0078 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1236 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0080 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1244 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0080 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1244 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0068 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1228 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0068 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1228 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0055 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1209 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.0055 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1209 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0047 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1197 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0047 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1197 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0041 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1190 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0041 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1190 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0036 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1180 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0036 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1180 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0030 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1166 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.0030 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1166 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0024 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1153 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 0.0024 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1153 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0019 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1143 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.0019 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1143 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0016 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1136 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0016 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1136 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0013 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1132 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0013 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1132 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0011 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1129 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0011 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1129 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 0.0010 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1126 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0010 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1126 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 9.0643e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1125 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 9.0643e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1125 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 8.2113e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1123 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.2113e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1123 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 7.5139e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1122 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 7.5139e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1122 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 6.9391e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1122 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.9391e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1122 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 6.4623e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1121 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 6.4623e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1121 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 6.0643e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1120 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 6.0643e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1120 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 5.7316e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1120 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.7316e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1120 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 5.4483e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1120 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.4483e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1120 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 5.1968e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1119 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 5.1968e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1119 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 4.9735e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1119 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.9735e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1119 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 4.7703e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1119 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.7703e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1119 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 4.5835e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1118 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 4.5835e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1118 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 4.4039e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1118 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.4039e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1118 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 4.2286e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1118 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 4.2286e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1118 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 4.0535e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1118 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 4.0535e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1118 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 3.8802e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1117 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8802e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1117 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 3.7104e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1117 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7104e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1117 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 3.5452e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1117 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 3.5452e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1117 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 3.3857e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1116 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 3.3857e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1116 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 3.2325e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1116 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 3.2325e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1116 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 3.0872e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1116 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 3.0872e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1116 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.9517e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1116 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 2.9517e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1116 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.8249e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1116 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 2.8249e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1116 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.7070e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1115 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 2.7070e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1115 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.5981e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1115 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5981e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1115 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.4978e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1115 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 2.4978e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1115 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.4058e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1115 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 2.4058e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1115 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.3219e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1115 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 2.3219e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1115 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.2451e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1115 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2451e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1115 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.1749e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1749e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.1104e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 2.1104e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 2.0512e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0512e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.9950e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 1.9950e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.9437e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 1.9437e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.9061e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9061e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.8547e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8547e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.8109e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 1.8109e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.7637e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7637e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.7231e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7231e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.6850e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6850e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.6435e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6435e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.6124e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6124e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.5807e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1114 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 1.5807e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1114 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.5484e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5484e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.5165e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5165e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.4857e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 1.4857e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.4566e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 1.4566e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.4308e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4308e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.4045e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4045e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.3779e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 1.3779e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.3541e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 1.3541e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.3309e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3309e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.3083e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3083e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.2862e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2862e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.2646e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 1.2646e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.2425e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 1.2425e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.2169e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2169e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.1928e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1928e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.1715e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1715e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.1496e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 1.1496e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.1260e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1260e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.1032e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1032e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.0867e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0867e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.0697e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0697e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.0517e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0517e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.0345e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 1.0345e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.0197e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 1.0197e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 1.0069e-04 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0069e-04 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 9.9122e-05 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.9122e-05 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 9.7651e-05 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.7651e-05 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 9.6336e-05 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1113 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.6336e-05 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1113 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 9.5087e-05 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1112 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.5087e-05 - macro_f1_score: 0.8889 - soft_f1_loss: 0.1112 - AUC: 0.8889 - global_accuracy: 1.0000 - global_precision: 1.0000 - global_recall: 1.0000 - val_loss: 9.3855e-05 - val_macro_f1_score: 0.8889 - val_soft_f1_loss: 0.1112 - val_AUC: 0.8889 - val_global_accuracy: 1.0000 - val_global_precision: 1.0000 - val_global_recall: 1.0000\n",
      "@_@\t\n",
      "@_@\t------------------ Training Round Summary ------------------\n",
      "@_@\tTraining took 0h:1m:44s\n",
      "@_@\thistory of metrics:\n",
      "@_@\t\tloss: [2.025174140930176, 1.0588937997817993, 0.5619244575500488, 0.4289954900741577, 0.3515947163105011, 0.19453087449073792, 0.14452245831489563, 0.11968027055263519, 0.06616824865341187, 0.025294121354818344, 0.015434889122843742, 0.012069109827280045, 0.008403550833463669, 0.007210494950413704, 0.007793836761265993, 0.007967481389641762, 0.006840251386165619, 0.005513803567737341, 0.0046566142700612545, 0.004126290790736675, 0.0036187637597322464, 0.002998493378981948, 0.0024160437751561403, 0.0019417200237512589, 0.001600542338564992, 0.0013431152328848839, 0.0011496366932988167, 0.0010120865190401673, 0.0009064336773008108, 0.0008211291860789061, 0.0007513927412219346, 0.0006939090089872479, 0.0006462261080741882, 0.0006064340705052018, 0.0005731576238758862, 0.0005448292940855026, 0.0005196849815547466, 0.000497350178193301, 0.0004770269151777029, 0.0004583496483974159, 0.00044038769556209445, 0.0004228613106533885, 0.00040534764411859214, 0.00038801925256848335, 0.0003710438613779843, 0.00035452423617243767, 0.0003385732998140156, 0.00032324876519851387, 0.0003087215591222048, 0.0002951680507976562, 0.0002824922848958522, 0.00027070427313447, 0.00025980593636631966, 0.00024977553403005004, 0.0002405811392236501, 0.00023218704154714942, 0.000224511677515693, 0.00021748665312770754, 0.00021103676408529282, 0.00020511835464276373, 0.00019949687703046948, 0.00019436745787970722, 0.00019060506019741297, 0.0001854665606515482, 0.00018108991207554936, 0.00017636653501540422, 0.00017231469973921776, 0.0001684986345935613, 0.00016435043653473258, 0.00016124415560625494, 0.00015806834562681615, 0.0001548436121083796, 0.0001516546617494896, 0.00014856530469842255, 0.00014566471509169787, 0.00014307591482065618, 0.00014045211719349027, 0.00013779461733065546, 0.00013540618238039315, 0.0001330875384155661, 0.00013082625810056925, 0.00012861804862041026, 0.00012645973765756935, 0.000124251440865919, 0.00012169376714155078, 0.0001192841591546312, 0.00011714849097188562, 0.00011495515354909003, 0.0001126003116951324, 0.00011031622852897272, 0.00010867194941965863, 0.00010696857498260215, 0.00010516583279240876, 0.00010344636393710971, 0.00010196518269367516, 0.000100688572274521, 9.912187670124695e-05, 9.765094000613317e-05, 9.633593435864896e-05, 9.508745279163122e-05]\n",
      "@_@\t\tmacro_f1_score: [0.26543208956718445, 0.20185185968875885, 0.395061731338501, 0.7104377746582031, 0.7474747896194458, 0.7333333492279053, 0.7333333492279053, 0.7174603343009949, 0.8507936596870422, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272]\n",
      "@_@\t\tsoft_f1_loss: [0.7205884456634521, 0.7240021228790283, 0.5657719373703003, 0.3795968294143677, 0.3093215227127075, 0.29540884494781494, 0.29440969228744507, 0.2835119068622589, 0.18504460155963898, 0.14451582729816437, 0.12968061864376068, 0.12521888315677643, 0.12221058458089828, 0.12186729907989502, 0.12355184555053711, 0.12436266988515854, 0.12283476442098618, 0.12088939547538757, 0.11972292512655258, 0.11896851658821106, 0.11795245110988617, 0.11655926704406738, 0.11527548730373383, 0.1143009141087532, 0.1136438325047493, 0.1131819635629654, 0.11285299807786942, 0.1126299574971199, 0.11246658861637115, 0.11234084516763687, 0.11224184930324554, 0.11216288059949875, 0.11209896206855774, 0.11204618960618973, 0.1120021864771843, 0.11196412146091461, 0.11192980408668518, 0.11189822107553482, 0.11186838150024414, 0.11183978617191315, 0.11181150376796722, 0.11178335547447205, 0.11175478994846344, 0.1117262989282608, 0.11169826984405518, 0.11167102307081223, 0.11164474487304688, 0.11161956191062927, 0.11159580200910568, 0.111573725938797, 0.11155310273170471, 0.11153391003608704, 0.11151613295078278, 0.1114998385310173, 0.11148487031459808, 0.11147113889455795, 0.11145862936973572, 0.11144716292619705, 0.11143665760755539, 0.11142703890800476, 0.11141765117645264, 0.1114090159535408, 0.11140318959951401, 0.11139462888240814, 0.1113874539732933, 0.11137989908456802, 0.11137381196022034, 0.11136778444051743, 0.11136078834533691, 0.11135591566562653, 0.11135092377662659, 0.11134583503007889, 0.11134081333875656, 0.11133596301078796, 0.11133139580488205, 0.11132737994194031, 0.11132332682609558, 0.11131911724805832, 0.11131540685892105, 0.11131182312965393, 0.11130829900503159, 0.11130484193563461, 0.11130145192146301, 0.11129800230264664, 0.11129365861415863, 0.11128931492567062, 0.11128544807434082, 0.11128149926662445, 0.11127743124961853, 0.11127357929944992, 0.11127110570669174, 0.11126828193664551, 0.11126502603292465, 0.1112617552280426, 0.11125887930393219, 0.11125656962394714, 0.11125417798757553, 0.11125213652849197, 0.11125031858682632, 0.11124853044748306]\n",
      "@_@\t\tAUC: [0.5246031880378723, 0.6706018447875977, 0.7680555582046509, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272]\n",
      "@_@\t\tglobal_accuracy: [0.5416666865348816, 0.7083333134651184, 0.8333333134651184, 0.9305555820465088, 0.9444444179534912, 0.9444444179534912, 0.9583333134651184, 0.9444444179534912, 0.9722222089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "@_@\t\tglobal_precision: [0.2857142984867096, 0.5, 0.8461538553237915, 0.8636363744735718, 0.8695651888847351, 0.9047619104385376, 0.949999988079071, 0.9473684430122375, 0.9523809552192688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "@_@\t\tglobal_recall: [0.380952388048172, 0.380952388048172, 0.523809552192688, 0.9047619104385376, 0.9523809552192688, 0.9047619104385376, 0.9047619104385376, 0.8571428656578064, 0.9523809552192688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "@_@\t\tval_loss: [1.0588936805725098, 0.5619244575500488, 0.4289954900741577, 0.3515947163105011, 0.19453087449073792, 0.14452245831489563, 0.11968027055263519, 0.06616824865341187, 0.025294121354818344, 0.015434888191521168, 0.012069109827280045, 0.008403550833463669, 0.007210494950413704, 0.007793836761265993, 0.007967481389641762, 0.006840250920504332, 0.005513803567737341, 0.004656613804399967, 0.004126290790736675, 0.0036187637597322464, 0.002998493378981948, 0.0024160435423254967, 0.0019417201401665807, 0.001600542338564992, 0.0013431152328848839, 0.0011496365768834949, 0.0010120866354554892, 0.0009064336773008108, 0.0008211291860789061, 0.0007513927412219346, 0.0006939090089872479, 0.0006462261080741882, 0.0006064340705052018, 0.0005731576820835471, 0.0005448292358778417, 0.0005196849815547466, 0.000497350178193301, 0.0004770269733853638, 0.0004583496483974159, 0.00044038769556209445, 0.0004228613106533885, 0.0004053476150147617, 0.00038801925256848335, 0.0003710438613779843, 0.00035452423617243767, 0.0003385733289178461, 0.00032324876519851387, 0.0003087215591222048, 0.0002951680507976562, 0.00028249225579202175, 0.00027070427313447, 0.0002598059072624892, 0.00024977553403005004, 0.0002405811392236501, 0.00023218704154714942, 0.000224511677515693, 0.0002174866385757923, 0.00021103676408529282, 0.00020511835464276373, 0.00019949687703046948, 0.00019436745787970722, 0.00019060506019741297, 0.0001854665606515482, 0.00018108991207554936, 0.00017636653501540422, 0.00017231469973921776, 0.0001684986345935613, 0.00016435043653473258, 0.0001612441410543397, 0.00015806834562681615, 0.0001548436121083796, 0.0001516546617494896, 0.00014856530469842255, 0.00014566471509169787, 0.00014307591482065618, 0.00014045211719349027, 0.00013779460277874023, 0.00013540618238039315, 0.0001330875384155661, 0.00013082625810056925, 0.00012861804862041026, 0.00012645973765756935, 0.000124251440865919, 0.00012169375986559317, 0.00011928416643058881, 0.00011714849097188562, 0.00011495515354909003, 0.0001126003116951324, 0.00011031622852897272, 0.00010867194941965863, 0.00010696857498260215, 0.00010516583279240876, 0.00010344636393710971, 0.00010196517541771755, 0.000100688572274521, 9.912188397720456e-05, 9.765093273017555e-05, 9.633593435864896e-05, 9.508744551567361e-05, 9.38545708777383e-05]\n",
      "@_@\t\tval_macro_f1_score: [0.20185185968875885, 0.395061731338501, 0.7104377746582031, 0.7474747896194458, 0.7333333492279053, 0.7333333492279053, 0.7174603343009949, 0.8507936596870422, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272]\n",
      "@_@\t\tval_soft_f1_loss: [0.7240021228790283, 0.5657719373703003, 0.3795968294143677, 0.3093215227127075, 0.29540884494781494, 0.2944096624851227, 0.2835119068622589, 0.18504460155963898, 0.14451582729816437, 0.12968061864376068, 0.12521888315677643, 0.12221058458089828, 0.12186729907989502, 0.12355184555053711, 0.12436266988515854, 0.12283476442098618, 0.12088939547538757, 0.11972293257713318, 0.11896851658821106, 0.11795245110988617, 0.11655926704406738, 0.11527548730373383, 0.1143009290099144, 0.1136438325047493, 0.1131819635629654, 0.11285299807786942, 0.1126299574971199, 0.11246658861637115, 0.11234084516763687, 0.11224184930324554, 0.11216288059949875, 0.11209896206855774, 0.11204618960618973, 0.1120021864771843, 0.11196412146091461, 0.11192978918552399, 0.11189821362495422, 0.11186838150024414, 0.11183978617191315, 0.11181150376796722, 0.11178335547447205, 0.11175478994846344, 0.1117262989282608, 0.11169826984405518, 0.11167102307081223, 0.11164474487304688, 0.11161956191062927, 0.11159580200910568, 0.111573725938797, 0.11155310273170471, 0.11153391003608704, 0.11151613295078278, 0.1114998385310173, 0.11148485541343689, 0.11147113889455795, 0.11145862936973572, 0.11144716292619705, 0.11143665760755539, 0.11142703890800476, 0.11141765117645264, 0.1114090159535408, 0.11140317469835281, 0.11139462888240814, 0.1113874614238739, 0.11137991398572922, 0.11137381941080093, 0.11136779189109802, 0.1113608181476593, 0.11135591566562653, 0.11135092377662659, 0.11134583503007889, 0.11134081333875656, 0.11133596301078796, 0.11133139580488205, 0.11132737994194031, 0.11132332682609558, 0.11131911724805832, 0.11131539940834045, 0.11131180822849274, 0.11130829900503159, 0.11130484938621521, 0.11130145192146301, 0.11129800230264664, 0.11129365861415863, 0.11128932982683182, 0.11128544807434082, 0.11128149926662445, 0.11127743124961853, 0.11127356439828873, 0.11127109080553055, 0.11126828193664551, 0.11126502603292465, 0.1112617552280426, 0.11125887930393219, 0.11125656962394714, 0.11125417798757553, 0.11125213652849197, 0.11125031858682632, 0.11124853044748306, 0.11124666780233383]\n",
      "@_@\t\tval_AUC: [0.6706018447875977, 0.7680555582046509, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272, 0.8888888955116272]\n",
      "@_@\t\tval_global_accuracy: [0.7083333134651184, 0.8333333134651184, 0.9305555820465088, 0.9444444179534912, 0.9444444179534912, 0.9583333134651184, 0.9444444179534912, 0.9722222089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "@_@\t\tval_global_precision: [0.5, 0.8461538553237915, 0.8636363744735718, 0.8695651888847351, 0.9047619104385376, 0.949999988079071, 0.9473684430122375, 0.9523809552192688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "@_@\t\tval_global_recall: [0.380952388048172, 0.523809552192688, 0.9047619104385376, 0.9523809552192688, 0.9047619104385376, 0.9047619104385376, 0.8571428656578064, 0.9523809552192688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "@_@\tSaving to /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-transfer-miniBatchTest_2024-04-02_1952/0_unfrozen_block/figs/learning_curve.png\n",
      "@_@\tValidation loss: 0.0001\n",
      "@_@\tValidation Macro F1-score: 0.8889\n",
      "W0402 19:55:08.429375 129459121858368 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-transfer-miniBatchTest_2024-04-02_1952/0_unfrozen_block/model/saved_model/assets\n",
      "I0402 19:55:10.191320 129459121858368 builder_impl.py:797] Assets written to: /mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-transfer-miniBatchTest_2024-04-02_1952/0_unfrozen_block/model/saved_model/assets\n",
      "@_@\tSaved model to: \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/out/vgg16-transfer-miniBatchTest_2024-04-02_1952/0_unfrozen_block/model/saved_model\"\n",
      "@_@\t\n",
      "@_@\t------------------ Setup Round ------------------\n",
      "@_@\tUnfreezing 1 blocks...\n",
      "@_@\tTotal trainable weights: 12\n",
      "@_@\t\tblock5_conv1/kernel:0\n",
      "@_@\t\tblock5_conv1/bias:0\n",
      "@_@\t\tblock5_conv2/kernel:0\n",
      "@_@\t\tblock5_conv2/bias:0\n",
      "@_@\t\tblock5_conv3/kernel:0\n",
      "@_@\t\tblock5_conv3/bias:0\n",
      "@_@\t\tmy_fc_1/kernel:0\n",
      "@_@\t\tmy_fc_1/bias:0\n",
      "@_@\t\tmy_fc_2/kernel:0\n",
      "@_@\t\tmy_fc_2/bias:0\n",
      "@_@\t\tmy_output/kernel:0\n",
      "@_@\t\tmy_output/bias:0\n",
      "@_@\tLearning rate = 1e-05\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/jupyter/../neural_nets/vgg16_test.py\", line 449, in <module>\n",
      "    app.run(main)\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/mycode/jupyter/../neural_nets/vgg16_test.py\", line 403, in main\n",
      "    model.load_weights(latest)\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py\", line 368, in is_hdf5_filepath\n",
      "    filepath.endswith(\".h5\")\n",
      "AttributeError: 'NoneType' object has no attribute 'endswith'\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch Testing\n",
    "!python ../neural_nets/vgg16_test.py \\\n",
    "    --ouput_name=vgg16-transfer-miniBatchTest \\\n",
    "    --image_size=224 --epochs=100 --batch_size=8 --train_size=8 \\\n",
    "    --mode=train_then_eval --min_unfreeze_blocks=0 --max_unfreeze_blocks=3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
